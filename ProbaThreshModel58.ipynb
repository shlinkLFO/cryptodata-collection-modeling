{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "# Feature Engineering Imports\n",
    "import pandas_ta as ta  # Technical indicators\n",
    "\n",
    "# Modeling Imports\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore') # General suppression\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Data Loading\n",
    "CSV_FILE_PATH = r'C:\\Users\\mason\\AVP\\BTCUSD.csv' # Use raw string for Windows paths\n",
    "SYMBOL_NAME = 'BTCUSD' # Define the symbol represented in the CSV\n",
    "\n",
    "# Feature Selection (Using the list provided)\n",
    "SELECTED_FEATURE_NAMES = [\n",
    "    'Volume BTC', 'Volume USD', 'bband_width_20h', 'cci_20h', 'close_pos_in_range',\n",
    "    'cmf_20h', 'day_0', 'day_1', 'day_2', 'day_4', 'day_5', 'day_6', 'hour_0',\n",
    "    'hour_1', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
    "    'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_2', 'hour_20', 'hour_21',\n",
    "    'hour_22', 'hour_23', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_8',\n",
    "    'hour_9', 'lag_12h_price_return', 'lag_12h_volume_return', 'lag_168h_price_return',\n",
    "    'lag_24h_price_return', 'lag_24h_volume_return', 'lag_3h_volume_return',\n",
    "    'lag_48h_price_return', 'lag_6h_volume_return', 'lag_72h_price_return',\n",
    "    'macd_hist', 'macd_signal', 'rolling_kurt_24h', 'rolling_skew_24h',\n",
    "    'rolling_std_168h', 'rolling_std_3h_sq', 'rolling_std_48h', 'rolling_std_6h',\n",
    "    'std12_div_std72', 'volume_btc_x_range', 'volume_div_ma_24h', 'volume_ma_12h',\n",
    "    'volume_ma_168h', 'volume_return_1h'\n",
    "]\n",
    "\n",
    "# Modeling & Walk-Forward\n",
    "TARGET_THRESHOLD_PCT = 0.1 # Target threshold percentage variable\n",
    "\n",
    "# Walk-forward params (Suggestions for hourly data)\n",
    "TRAIN_WINDOW_HOURS = int(24 * 30 * 1.5) # Approx 1.5 months training (~1080 hours)\n",
    "TEST_WINDOW_HOURS = 24 * 3           # Predict next 3 days (72 hours)\n",
    "STEP_HOURS = 24                      # Step forward 1 day\n",
    "\n",
    "# Convert time durations to rows (assuming 1 row = 1 hour)\n",
    "TRAIN_WINDOW_ROWS = TRAIN_WINDOW_HOURS\n",
    "TEST_WINDOW_ROWS = TEST_WINDOW_HOURS\n",
    "STEP_ROWS = STEP_HOURS\n",
    "\n",
    "# Inner Cross-Validation Grid Search Configuration (Keep small)\n",
    "INNER_CV_PARAM_GRID = {\n",
    "    'max_depth': [3, 4],         # Keep shallow\n",
    "    'n_estimators': [100, 150],  # Moderate number\n",
    "    'eta': [0.05, 0.1],          # Learning rate\n",
    "    # Add other params to tune if desired, e.g., 'subsample', 'colsample_bytree'\n",
    "}\n",
    "INNER_CV_VALIDATION_PCT = 0.20 # Use last 20% of training data for quick validation\n",
    "\n",
    "# Fixed XGBoost parameters (Suggestions)\n",
    "XGB_FIXED_PARAMS = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',    # Logloss is common for probability calibration\n",
    "    'colsample_bytree': 0.7,     # Feature fraction per tree\n",
    "    'subsample': 0.8,            # Data fraction per tree\n",
    "    'min_child_weight': 3,       # Regularization\n",
    "    'gamma': 0.1,                # Regularization\n",
    "    'lambda': 1.5,               # L2 regularization\n",
    "    'alpha': 0.1,                # L1 regularization\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,                # Use all available CPU cores\n",
    "    'tree_method': 'hist',       # Efficient for CPU and handles NaNs\n",
    "    'use_label_encoder': False,  # Recommended to set explicitly\n",
    "    # 'enable_categorical': True # Set if using categorical features directly (not needed here)\n",
    "    # Add GPU params if desired and available:\n",
    "    # 'tree_method': 'gpu_hist',\n",
    "    # 'predictor': 'gpu_predictor'\n",
    "}\n",
    "\n",
    "# Probability Threshold Tuning Configuration\n",
    "THRESHOLD_SEARCH_RANGE = np.arange(0.10, 0.90, 0.05) # Search thresholds from 0.1 to 0.85\n",
    "\n",
    "# --- Feature Engineering Function (Optimized for 58 Features) ---\n",
    "\n",
    "def calculate_selected_features(df, symbol):\n",
    "    \"\"\"Calculates only the 58 pre-selected features.\"\"\"\n",
    "    print(\"Starting calculation of selected 58 features...\")\n",
    "    if df is None or len(df) < 3: return pd.DataFrame()\n",
    "    df = df.copy()\n",
    "    df['symbol'] = symbol\n",
    "\n",
    "    # --- Timestamp and Index ---\n",
    "    if 'timestamp' not in df.columns: return pd.DataFrame()\n",
    "    try: df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    except Exception: return pd.DataFrame()\n",
    "    df = df.sort_values('timestamp').dropna(subset=['timestamp'])\n",
    "    df = df.set_index('timestamp', drop=False)\n",
    "\n",
    "    # --- Volume Columns ---\n",
    "    if 'Volume BTC' in df.columns: df['volume_btc'] = df['Volume BTC']\n",
    "    else: df['volume_btc'] = 0\n",
    "    if 'Volume USD' in df.columns: df['volume_usd'] = df['Volume USD']\n",
    "    else: df['volume_usd'] = 0\n",
    "\n",
    "    # --- Basic Checks ---\n",
    "    required_ohlc = ['open', 'high', 'low', 'close']\n",
    "    for col in required_ohlc:\n",
    "        if col not in df.columns: return pd.DataFrame()\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    if df[required_ohlc].isnull().any().any():\n",
    "        df = df.dropna(subset=required_ohlc)\n",
    "    if df.empty: return pd.DataFrame()\n",
    "\n",
    "    # --- Feature Calculation Prerequisites (Calculate things needed by the 58) ---\n",
    "    min_periods_base = 2\n",
    "    # Need MA24 for volume_div_ma_24h\n",
    "    if len(df) >= 24:\n",
    "        df['ma_24h_temp'] = df['close'].rolling(window=24, min_periods=min_periods_base).mean()\n",
    "    else: df['ma_24h_temp'] = np.nan\n",
    "    # Need std12 and std72 for std12_div_std72\n",
    "    if len(df) >= 12:\n",
    "        df['rolling_std_12h_temp'] = df['close'].rolling(window=12, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_12h_temp'] = np.nan\n",
    "    if len(df) >= 72:\n",
    "        df['rolling_std_72h_temp'] = df['close'].rolling(window=72, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_72h_temp'] = np.nan\n",
    "    # Need base MACD components for macd_signal and macd_hist\n",
    "    if len(df) >= 26:\n",
    "        ema_12 = df['close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "        ema_26 = df['close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "        df['macd_temp'] = ema_12 - ema_26\n",
    "    else: df['macd_temp'] = np.nan\n",
    "    # Need H/L/C for close_pos_in_range\n",
    "    df['price_range_pct_temp'] = (df['high'] - df['low']) / df['low'] # Needed for volume_btc_x_range\n",
    "\n",
    "    # --- Calculate the 58 Selected Features ---\n",
    "\n",
    "    # Time Features\n",
    "    hour_of_day = df.index.hour\n",
    "    day_of_week = df.index.dayofweek\n",
    "    selected_hours = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "    selected_days = [0, 1, 2, 4, 5, 6]\n",
    "    for hour in selected_hours: df[f'hour_{hour}'] = (hour_of_day == hour).astype(int)\n",
    "    for day in selected_days: df[f'day_{day}'] = (day_of_week == day).astype(int)\n",
    "\n",
    "    # Volume Features (Directly requested)\n",
    "    df['Volume BTC'] = df['volume_btc']\n",
    "    df['Volume USD'] = df['volume_usd']\n",
    "    df['volume_return_1h'] = df['volume_btc'].pct_change()\n",
    "    for hours in [12, 168]:\n",
    "        if len(df) >= hours: df[f'volume_ma_{hours}h'] = df['volume_btc'].rolling(window=hours, min_periods=min_periods_base).mean()\n",
    "        else: df[f'volume_ma_{hours}h'] = np.nan\n",
    "    if 'ma_24h_temp' in df.columns: # Use prerequisite\n",
    "         with np.errstate(divide='ignore', invalid='ignore'):\n",
    "              df['volume_div_ma_24h'] = df['volume_btc'] / df['ma_24h_temp']\n",
    "    else: df['volume_div_ma_24h'] = np.nan\n",
    "    if 'price_range_pct_temp' in df.columns: # Use prerequisite\n",
    "         df['volume_btc_x_range'] = df['volume_btc'] * df['price_range_pct_temp']\n",
    "    else: df['volume_btc_x_range'] = np.nan\n",
    "\n",
    "\n",
    "    # Lagged Returns\n",
    "    for hours in [12, 24, 48, 72, 168]: df[f'lag_{hours}h_price_return'] = df['close'].pct_change(periods=hours)\n",
    "    for hours in [3, 6, 12, 24]: df[f'lag_{hours}h_volume_return'] = df['volume_btc'].pct_change(periods=hours)\n",
    "\n",
    "    # Rolling Stats\n",
    "    if len(df) >= 6: df['rolling_std_6h'] = df['close'].rolling(window=6, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_6h'] = np.nan\n",
    "    if len(df) >= 48: df['rolling_std_48h'] = df['close'].rolling(window=48, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_48h'] = np.nan\n",
    "    if len(df) >= 168: df['rolling_std_168h'] = df['close'].rolling(window=168, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_168h'] = np.nan\n",
    "    if len(df) >= 3: df['rolling_std_3h_sq'] = (df['close'].rolling(window=3, min_periods=min_periods_base).std())**2\n",
    "    else: df['rolling_std_3h_sq'] = np.nan\n",
    "    if len(df) >= 24:\n",
    "        df['rolling_skew_24h'] = df['close'].pct_change().rolling(window=24, min_periods=24).skew()\n",
    "        df['rolling_kurt_24h'] = df['close'].pct_change().rolling(window=24, min_periods=24).kurt()\n",
    "    else: df['rolling_skew_24h'], df['rolling_kurt_24h'] = np.nan, np.nan\n",
    "\n",
    "    # MACD Features (using prerequisite)\n",
    "    if 'macd_temp' in df.columns and len(df) >= 35: # Need 26 for macd_temp + 9 for signal\n",
    "        df['macd_signal'] = df['macd_temp'].ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "        df['macd_hist'] = df['macd_temp'] - df['macd_signal']\n",
    "    else: df['macd_signal'], df['macd_hist'] = np.nan, np.nan\n",
    "\n",
    "    # Ratio Feature (using prerequisites)\n",
    "    if 'rolling_std_12h_temp' in df.columns and 'rolling_std_72h_temp' in df.columns:\n",
    "         with np.errstate(divide='ignore', invalid='ignore'):\n",
    "             df['std12_div_std72'] = df['rolling_std_12h_temp'] / df['rolling_std_72h_temp']\n",
    "    else: df['std12_div_std72'] = np.nan\n",
    "\n",
    "    # TA-Lib Features\n",
    "    ta_df = df.rename(columns={'volume_btc': 'volume'}, errors='ignore')\n",
    "    if all(c in ta_df.columns for c in ['high', 'low', 'close']):\n",
    "        # Bollinger Bands (Width only)\n",
    "        try:\n",
    "            bbands_df = ta_df.ta.bbands(length=20, std=2)\n",
    "            if bbands_df is not None: df['bband_width_20h'] = bbands_df.get(f'BBB_20_2.0', np.nan)\n",
    "            else: df['bband_width_20h'] = np.nan\n",
    "        except Exception: df['bband_width_20h'] = np.nan\n",
    "        # CCI\n",
    "        try: df['cci_20h'] = ta_df.ta.cci(length=20)\n",
    "        except Exception: df['cci_20h'] = np.nan\n",
    "        # CMF\n",
    "        if 'volume' in ta_df.columns:\n",
    "             try: df['cmf_20h'] = ta_df.ta.cmf(length=20)\n",
    "             except Exception: df['cmf_20h'] = np.nan\n",
    "        else: df['cmf_20h'] = np.nan\n",
    "    else: # Set TA features to NaN if base columns missing\n",
    "        df['bband_width_20h'], df['cci_20h'], df['cmf_20h'] = np.nan, np.nan, np.nan\n",
    "\n",
    "    # Position in Range\n",
    "    range_hl = df['high'] - df['low']\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['close_pos_in_range'] = ((df['close'] - df['low']) / range_hl).fillna(0.5).replace([np.inf, -np.inf], 0.5)\n",
    "\n",
    "    # --- Final Selection & Cleanup ---\n",
    "    # Select only the columns explicitly listed, plus timestamp and symbol for joining/sorting\n",
    "    final_feature_cols_to_keep = [f for f in SELECTED_FEATURE_NAMES if f in df.columns]\n",
    "    essential_cols = ['timestamp', 'symbol', 'open', 'high', 'low', 'close'] # Keep OHLC for target creation\n",
    "    df_final = df[essential_cols + final_feature_cols_to_keep].copy()\n",
    "\n",
    "    # Drop temporary prerequisite columns\n",
    "    temp_cols = [c for c in df_final.columns if c.endswith('_temp')]\n",
    "    df_final = df_final.drop(columns=temp_cols, errors='ignore')\n",
    "\n",
    "    # Reset index and final check for infinities\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    df_final = df_final.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    print(f\"Selected feature calculation finished. Returning {len(df_final)} rows with {len(df_final.columns)} columns.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"--- 1. Data Loading & Initial Prep ---\")\n",
    "    try:\n",
    "        print(f\"Loading data from: {CSV_FILE_PATH}\")\n",
    "        col_names = ['unix', 'date', 'symbol_csv', 'open', 'high', 'low', 'close', 'Volume BTC', 'Volume USD']\n",
    "        df_raw = pd.read_csv(CSV_FILE_PATH, header=0, names=col_names)\n",
    "        print(f\"Raw data loaded. Shape: {df_raw.shape}\")\n",
    "\n",
    "        df_raw['timestamp'] = pd.to_datetime(df_raw['date'])\n",
    "        df_raw = df_raw.drop(['unix', 'date', 'symbol_csv'], axis=1)\n",
    "        df_raw = df_raw.sort_values('timestamp').reset_index(drop=True)\n",
    "        if df_raw.empty: exit(\"DataFrame empty after loading. Exiting.\")\n",
    "        print(f\"Initial data prep done. Shape: {df_raw.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing CSV: {e}\"); traceback.print_exc(); exit()\n",
    "\n",
    "    print(\"\\n--- 2. Feature Engineering (Selected Features) ---\")\n",
    "    feature_calc_start = time.time()\n",
    "    df_features = calculate_selected_features(df_raw, symbol=SYMBOL_NAME)\n",
    "    feature_calc_end = time.time()\n",
    "    if df_features.empty: exit(\"Feature calculation failed. Exiting.\")\n",
    "    print(f\"Feature calculation completed in {feature_calc_end - feature_calc_start:.2f} seconds.\")\n",
    "\n",
    "    # Double check if all selected features were actually generated\n",
    "    missing_features = [f for f in SELECTED_FEATURE_NAMES if f not in df_features.columns]\n",
    "    if missing_features:\n",
    "        print(f\"WARNING: The following expected features were NOT generated: {missing_features}\")\n",
    "        # Update the list to only include features that are actually present\n",
    "        CURRENT_FEATURE_COLS = [f for f in SELECTED_FEATURE_NAMES if f in df_features.columns]\n",
    "        print(f\"Using {len(CURRENT_FEATURE_COLS)} available features for modeling.\")\n",
    "    else:\n",
    "        CURRENT_FEATURE_COLS = SELECTED_FEATURE_NAMES\n",
    "        print(f\"All {len(CURRENT_FEATURE_COLS)} selected features generated successfully.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- 3. Data Cleaning (Post-Features) ---\")\n",
    "    # Replace inf/-inf with NaN (should already be done in function, but safety check)\n",
    "    df_features = df_features.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Drop rows where OHLC is NaN (should be handled in function)\n",
    "    # df_features = df_features.dropna(subset=['open', 'high', 'low', 'close'])\n",
    "\n",
    "    # Handle NaNs: XGBoost 'hist' tree method handles NaNs internally.\n",
    "    # Optional: Drop rows missing a *critical* feature if XGBoost handling isn't desired for it.\n",
    "    # Example: df = df_features.dropna(subset=['some_critical_feature'])\n",
    "    # We will proceed assuming XGBoost handles NaNs in CURRENT_FEATURE_COLS\n",
    "\n",
    "    # Final check for NaNs in feature columns (just for info)\n",
    "    nan_check = df_features[CURRENT_FEATURE_COLS].isnull().sum()\n",
    "    total_nans = nan_check.sum()\n",
    "    if total_nans > 0:\n",
    "        print(f\"Total NaNs found in feature columns: {total_nans} (XGBoost 'hist' method will handle them).\")\n",
    "        # print(nan_check[nan_check > 0]) # Uncomment to see counts per feature\n",
    "    else:\n",
    "        print(\"No NaNs found in feature columns.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- 4. Modeling Target & Final Prep ---\")\n",
    "    TARGET_COLUMN = 'target'\n",
    "    df = df_features.copy() # Use df from now on\n",
    "\n",
    "    # Create binary target\n",
    "    print(f\"Creating binary target '{TARGET_COLUMN}' ({TEST_WINDOW_HOURS}-hour return >= {TARGET_THRESHOLD_PCT}%)...\")\n",
    "    df = df.sort_values('timestamp') # Sort by time is crucial for shift\n",
    "    df['future_price'] = df['close'].shift(-TEST_WINDOW_ROWS)\n",
    "    df['price_return_future'] = (df['future_price'] - df['close']) / df['close'] * 100\n",
    "    df['target'] = (df['price_return_future'] >= TARGET_THRESHOLD_PCT).astype(int)\n",
    "    df = df.drop(['future_price', 'price_return_future'], axis=1)\n",
    "\n",
    "    target_nan_count = df['target'].isna().sum()\n",
    "    print(f\"NaN values in target before drop: {target_nan_count} (Expected: ~{TEST_WINDOW_ROWS})\")\n",
    "    df = df.dropna(subset=[TARGET_COLUMN]) # Drop rows where target cannot be calculated\n",
    "    print(f\"Rows after removing NaN targets: {len(df)}\")\n",
    "    if df.empty: exit(\"DataFrame empty after target creation/NaN drop. Exiting.\")\n",
    "\n",
    "    target_counts = df[TARGET_COLUMN].value_counts(normalize=True) * 100\n",
    "    print(\"\\nTarget variable distribution:\")\n",
    "    print(f\"  0 (< {TARGET_THRESHOLD_PCT}% return): {target_counts.get(0, 0):.2f}%\")\n",
    "    print(f\"  1 (>= {TARGET_THRESHOLD_PCT}% return): {target_counts.get(1, 0):.2f}%\")\n",
    "\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "    print(f\"Final DataFrame shape for backtesting: {df.shape}\")\n",
    "    print(f\"Number of features for modeling: {len(CURRENT_FEATURE_COLS)}\")\n",
    "\n",
    "\n",
    "    # --- 5. Walk-Forward Validation with Threshold Tuning ---\n",
    "    print(\"\\n--- 5. Starting Walk-Forward Validation ---\")\n",
    "    all_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    all_best_thresholds = []\n",
    "    feature_importances_gain = {feature: [] for feature in CURRENT_FEATURE_COLS}\n",
    "    iteration_count = 0\n",
    "\n",
    "    n_rows_total = len(df)\n",
    "    current_train_start_idx = 0\n",
    "    total_iterations_estimate = max(0, (n_rows_total - TRAIN_WINDOW_ROWS - TEST_WINDOW_ROWS) // STEP_ROWS + 1)\n",
    "    print(f\"Total rows: {n_rows_total}, Train Window: {TRAIN_WINDOW_ROWS} ({TRAIN_WINDOW_HOURS}h), Test Window: {TEST_WINDOW_ROWS} ({TEST_WINDOW_HOURS}h), Step: {STEP_ROWS} ({STEP_HOURS}h)\")\n",
    "    print(f\"Estimated iterations: {total_iterations_estimate}\")\n",
    "    print(f\"Inner CV Grid: {INNER_CV_PARAM_GRID}\")\n",
    "    print(f\"Threshold Search Range: {THRESHOLD_SEARCH_RANGE}\")\n",
    "    print(\"-\" * 30)\n",
    "    start_loop_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        # Define Window Boundaries\n",
    "        train_end_idx = current_train_start_idx + TRAIN_WINDOW_ROWS\n",
    "        test_start_idx = train_end_idx\n",
    "        test_end_idx = test_start_idx + TEST_WINDOW_ROWS\n",
    "\n",
    "        # Boundary Checks\n",
    "        if test_end_idx > n_rows_total:\n",
    "            print(f\"\\nStopping: Test window end index ({test_end_idx}) exceeds total rows ({n_rows_total}).\")\n",
    "            break\n",
    "        if current_train_start_idx >= n_rows_total:\n",
    "             print(f\"\\nStopping: Train window start index ({current_train_start_idx}) reached end.\")\n",
    "             break\n",
    "\n",
    "        # Data Slicing\n",
    "        train_df = df.iloc[current_train_start_idx : train_end_idx]\n",
    "        test_df = df.iloc[test_start_idx : test_end_idx]\n",
    "\n",
    "        # Data Validity Checks\n",
    "        min_train_samples = max(50, int(0.1 * TRAIN_WINDOW_ROWS))\n",
    "        min_test_samples = 5\n",
    "        if len(train_df) < min_train_samples or len(test_df) < min_test_samples:\n",
    "            print(f\"Skipping iter {iteration_count + 1}: Insufficient data train ({len(train_df)}/{min_train_samples}) or test ({len(test_df)}/{min_test_samples}).\")\n",
    "            current_train_start_idx += STEP_ROWS\n",
    "            continue\n",
    "\n",
    "        X_train_full = train_df[CURRENT_FEATURE_COLS]\n",
    "        y_train_full = train_df[TARGET_COLUMN]\n",
    "        X_test = test_df[CURRENT_FEATURE_COLS]\n",
    "        y_test = test_df[TARGET_COLUMN]\n",
    "\n",
    "        # Check for Single Class in Train/Test\n",
    "        train_counts = y_train_full.value_counts()\n",
    "        test_counts = y_test.value_counts()\n",
    "        if len(train_counts) < 2:\n",
    "            print(f\"Skipping iter {iteration_count + 1}: Full training data has only one class ({train_counts.index.tolist()}).\")\n",
    "            current_train_start_idx += STEP_ROWS\n",
    "            continue\n",
    "        # Warning for single class in test set is acceptable\n",
    "\n",
    "        # Calculate scale_pos_weight for class imbalance\n",
    "        neg_count = train_counts.get(0, 0)\n",
    "        pos_count = train_counts.get(1, 0)\n",
    "        scale_pos_weight_val = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "\n",
    "        # --- Inner Loop: Hyperparameter Tuning ---\n",
    "        iter_start_time = time.time()\n",
    "        best_inner_cv_score = -np.inf # Using F1 for inner CV evaluation\n",
    "        best_params_iter = None\n",
    "        best_model_for_thresholding = None # Store the best model from inner CV\n",
    "\n",
    "        val_size = int(len(X_train_full) * INNER_CV_VALIDATION_PCT)\n",
    "        if val_size < min_test_samples or (len(X_train_full) - val_size) < min_test_samples:\n",
    "            print(f\"Warning iter {iteration_count + 1}: Train subset or Val set too small for Inner CV. Using first param combo.\")\n",
    "            best_params_iter = list(ParameterGrid(INNER_CV_PARAM_GRID))[0]\n",
    "        else:\n",
    "            X_train_sub = X_train_full[:-val_size]\n",
    "            y_train_sub = y_train_full[:-val_size]\n",
    "            X_val = X_train_full[-val_size:]\n",
    "            y_val = y_train_full[-val_size:]\n",
    "\n",
    "            if len(y_val.unique()) < 2 or len(y_train_sub.unique()) < 2:\n",
    "                print(f\"Warning iter {iteration_count + 1}: Inner train ({len(y_train_sub.unique())} classes) or val ({len(y_val.unique())} classes) has only one class. Skipping Inner CV params search.\")\n",
    "                best_params_iter = list(ParameterGrid(INNER_CV_PARAM_GRID))[0]\n",
    "            else:\n",
    "                # Iterate through the small grid for hyperparameters\n",
    "                for params_cv in ParameterGrid(INNER_CV_PARAM_GRID):\n",
    "                    try:\n",
    "                        current_cv_params = {**XGB_FIXED_PARAMS, **params_cv}\n",
    "                        model_cv = XGBClassifier(**current_cv_params,\n",
    "                                                 scale_pos_weight=scale_pos_weight_val)\n",
    "                        model_cv.fit(X_train_sub, y_train_sub,\n",
    "                                     eval_set=[(X_val, y_val)], # Use validation set for early stopping\n",
    "                                     early_stopping_rounds=10, # Stop if validation score doesn't improve\n",
    "                                     verbose=False)\n",
    "\n",
    "                        # Evaluate on validation set using default 0.5 threshold for hyperparam selection\n",
    "                        y_pred_val_cv = model_cv.predict(X_val)\n",
    "                        val_score = f1_score(y_val, y_pred_val_cv, average='binary', pos_label=1, zero_division=0)\n",
    "\n",
    "                        if val_score > best_inner_cv_score:\n",
    "                            best_inner_cv_score = val_score\n",
    "                            best_params_iter = params_cv\n",
    "                            best_model_for_thresholding = model_cv # Store the actual best model\n",
    "\n",
    "                    except Exception as e_cv:\n",
    "                        print(f\"Error during inner CV iter {iteration_count + 1} with params {params_cv}: {e_cv}\")\n",
    "                        # Fallback if error occurs during CV\n",
    "                        if best_params_iter is None: best_params_iter = list(ParameterGrid(INNER_CV_PARAM_GRID))[0]\n",
    "\n",
    "        # Handle case where inner CV failed entirely or was skipped\n",
    "        if best_params_iter is None:\n",
    "            best_params_iter = list(ParameterGrid(INNER_CV_PARAM_GRID))[0] # Default to first combo\n",
    "\n",
    "        # --- Probability Threshold Tuning ---\n",
    "        best_threshold_iter = 0.5 # Default threshold\n",
    "        best_thresh_f1_score = -np.inf\n",
    "\n",
    "        # Ensure we have a validation set and a model to use\n",
    "        if val_size >= min_test_samples and best_model_for_thresholding is not None and len(y_val.unique()) == 2:\n",
    "            try:\n",
    "                # Get probabilities on the validation set from the best inner CV model\n",
    "                y_pred_proba_val = best_model_for_thresholding.predict_proba(X_val)[:, 1]\n",
    "\n",
    "                # Iterate through potential thresholds\n",
    "                for t in THRESHOLD_SEARCH_RANGE:\n",
    "                    y_pred_val_t = (y_pred_proba_val >= t).astype(int)\n",
    "                    current_f1 = f1_score(y_val, y_pred_val_t, average='binary', pos_label=1, zero_division=0)\n",
    "\n",
    "                    if current_f1 > best_thresh_f1_score:\n",
    "                        best_thresh_f1_score = current_f1\n",
    "                        best_threshold_iter = t # Found a better threshold\n",
    "\n",
    "            except Exception as e_thresh:\n",
    "                 print(f\"Error during threshold tuning iter {iteration_count + 1}: {e_thresh}. Using default threshold 0.5.\")\n",
    "                 best_threshold_iter = 0.5 # Revert to default on error\n",
    "        else:\n",
    "             print(f\"Skipping threshold tuning iter {iteration_count + 1} (validation set issue or model unavailable). Using default 0.5.\")\n",
    "             best_threshold_iter = 0.5\n",
    "\n",
    "        all_best_thresholds.append(best_threshold_iter)\n",
    "\n",
    "\n",
    "        # --- Train Final Model for this Iteration ---\n",
    "        final_iter_params = {**XGB_FIXED_PARAMS, **best_params_iter}\n",
    "\n",
    "        # Print progress less frequently\n",
    "        if (iteration_count == 0) or ((iteration_count + 1) % 20 == 0) or (test_end_idx >= n_rows_total):\n",
    "             print(f\"\\nIter {iteration_count + 1}/{total_iterations_estimate}: \"\n",
    "                   f\"Train Indices [{current_train_start_idx}:{train_end_idx-1}], \"\n",
    "                   f\"Test Indices [{test_start_idx}:{test_end_idx-1}]\")\n",
    "             print(f\"  Best Params: {best_params_iter}\")\n",
    "             print(f\"  Best Threshold (F1 on Val): {best_threshold_iter:.2f} (Val F1: {best_thresh_f1_score:.4f})\")\n",
    "\n",
    "        current_model = XGBClassifier(**final_iter_params,\n",
    "                                      scale_pos_weight=scale_pos_weight_val)\n",
    "\n",
    "        try:\n",
    "            # Train on the FULL training set for this window\n",
    "            current_model.fit(X_train_full, y_train_full, verbose=False)\n",
    "\n",
    "            # --- Prediction and Evaluation using Tuned Threshold ---\n",
    "            # 1. Get probabilities on the test set\n",
    "            y_pred_proba_test = current_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # 2. Apply the best threshold found for this fold\n",
    "            y_pred = (y_pred_proba_test >= best_threshold_iter).astype(int)\n",
    "\n",
    "            # 3. Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Use zero_division=0 to avoid warnings when a class isn't predicted\n",
    "            precision = precision_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0)\n",
    "\n",
    "            all_metrics['accuracy'].append(accuracy)\n",
    "            all_metrics['precision'].append(precision)\n",
    "            all_metrics['recall'].append(recall)\n",
    "            all_metrics['f1'].append(f1)\n",
    "\n",
    "            # --- Store Feature Importances ---\n",
    "            try:\n",
    "                fold_importances = current_model.get_booster().get_score(importance_type='gain')\n",
    "                for feature in CURRENT_FEATURE_COLS:\n",
    "                    feature_importances_gain[feature].append(fold_importances.get(feature, 0))\n",
    "            except Exception as e_imp:\n",
    "                print(f\"Warning: Could not get feature importance for iter {iteration_count + 1}: {e_imp}\")\n",
    "                for feature in CURRENT_FEATURE_COLS: feature_importances_gain[feature].append(np.nan)\n",
    "\n",
    "            iteration_count += 1 # Increment successful iteration count\n",
    "\n",
    "        except Exception as model_err:\n",
    "            print(f\"ERROR during model training or prediction in Iter {iteration_count + 1}: {model_err}\")\n",
    "            print(f\"  Train shape: {X_train_full.shape}, Test shape: {X_test.shape}\")\n",
    "            print(f\"  Train classes: {y_train_full.value_counts().to_dict()}, Test classes: {y_test.value_counts().to_dict()}\")\n",
    "            # Add NaN to metrics/importances if fold failed\n",
    "            for key in all_metrics: all_metrics[key].append(np.nan)\n",
    "            for feature in CURRENT_FEATURE_COLS: feature_importances_gain[feature].append(np.nan)\n",
    "            # No need to append to all_best_thresholds here as it's found before final fit\n",
    "\n",
    "        # --- Move to Next Window ---\n",
    "        current_train_start_idx += STEP_ROWS\n",
    "\n",
    "\n",
    "    end_loop_time = time.time()\n",
    "    print(\"-\" * 30)\n",
    "    loop_duration_minutes = (end_loop_time - start_loop_time) / 60\n",
    "    print(f\"Walk-Forward Validation finished in {end_loop_time - start_loop_time:.2f} seconds ({loop_duration_minutes:.2f} minutes).\")\n",
    "\n",
    "    # --- 6. Aggregate and Display Results ---\n",
    "    print(\"\\n--- 6. Final Results ---\")\n",
    "    # Use nanmean/nanstd to handle potential NaNs from skipped/failed iterations\n",
    "    if iteration_count > 0 and len(all_metrics['f1']) > 0:\n",
    "        # Filter out potential NaN entries before calculating mean/std\n",
    "        valid_f1 = [m for m in all_metrics['f1'] if not pd.isna(m)]\n",
    "        if not valid_f1:\n",
    "             print(\"\\nNo valid metrics recorded (all iterations might have failed).\")\n",
    "        else:\n",
    "            avg_accuracy = np.nanmean(all_metrics['accuracy'])\n",
    "            avg_precision = np.nanmean(all_metrics['precision'])\n",
    "            avg_recall = np.nanmean(all_metrics['recall'])\n",
    "            avg_f1 = np.nanmean(valid_f1) # Use nanmean on the original list\n",
    "\n",
    "            print(\"\\n--- Average Walk-Forward Validation Results (with Threshold Tuning) ---\")\n",
    "            print(f\"Total Folds Evaluated (Successful Iterations): {iteration_count}\")\n",
    "            print(f\"Target Threshold: {TARGET_THRESHOLD_PCT}% increase over {TEST_WINDOW_HOURS} hours\")\n",
    "            print(f\"Train Window: {TRAIN_WINDOW_HOURS}h, Test Window: {TEST_WINDOW_HOURS}h, Step: {STEP_HOURS}h\")\n",
    "            print(f\"Average Accuracy:  {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "            print(f\"Average Recall:    {avg_recall:.4f}\")\n",
    "            print(f\"Average F1-Score:  {avg_f1:.4f}\")\n",
    "\n",
    "            # Avg threshold used\n",
    "            avg_threshold = np.nanmean(all_best_thresholds)\n",
    "            std_threshold = np.nanstd(all_best_thresholds)\n",
    "            print(f\"\\nAverage Best Threshold Found (on validation set): {avg_threshold:.3f} (StdDev: {std_threshold:.3f})\")\n",
    "\n",
    "\n",
    "            std_accuracy = np.nanstd(all_metrics['accuracy'])\n",
    "            std_precision = np.nanstd(all_metrics['precision'])\n",
    "            std_recall = np.nanstd(all_metrics['recall'])\n",
    "            std_f1 = np.nanstd(valid_f1)\n",
    "            print(\"\\n--- Standard Deviation of Metrics Across Folds ---\")\n",
    "            print(f\"Std Dev Accuracy:  {std_accuracy:.4f}\")\n",
    "            print(f\"Std Dev Precision: {std_precision:.4f}\")\n",
    "            print(f\"Std Dev Recall:    {std_recall:.4f}\")\n",
    "            print(f\"Std Dev F1-Score:  {std_f1:.4f}\")\n",
    "\n",
    "            # --- Display Feature Importances ---\n",
    "            print(\"\\n--- Average Feature Importances (Gain) ---\")\n",
    "            avg_importances = {}\n",
    "            for f, imp_list in feature_importances_gain.items():\n",
    "                valid_imps = [imp for imp in imp_list if not pd.isna(imp)]\n",
    "                if valid_imps:\n",
    "                    avg_importances[f] = np.mean(valid_imps)\n",
    "                else:\n",
    "                    avg_importances[f] = 0 # Assign 0 if no valid importances recorded\n",
    "\n",
    "            sorted_importances = sorted(avg_importances.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "            print(\"Top 20 Features:\")\n",
    "            for i, (feature, importance) in enumerate(sorted_importances[:20]):\n",
    "                print(f\"  {i+1}. {feature}: {importance:.4f}\")\n",
    "\n",
    "            zero_importance_features = [f for f, imp in avg_importances.items() if imp == 0]\n",
    "            print(f\"\\nFeatures with Zero Average Importance ({len(zero_importance_features)}):\")\n",
    "            # print(sorted(zero_importance_features)) # Uncomment to list them\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo iterations were successfully completed or no metrics were recorded.\")\n",
    "\n",
    "    print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
