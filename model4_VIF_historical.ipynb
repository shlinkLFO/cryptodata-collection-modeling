{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF: Stands for Variance Inflation Factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: \n",
    "Measures how much the variance of an estimated regression coefficient increases due to multicollinearity (correlation between predictor variables).\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "-Quantifies how well one predictor feature can be explained by all other predictor features in the model.\n",
    "\n",
    "-High VIF: The feature is highly correlated with other features; its information is largely redundant.\n",
    "\n",
    "-Low VIF: The feature is relatively independent of other features.\n",
    "\n",
    "\n",
    "Common Thresholds (Rules of Thumb):\n",
    "\n",
    "-VIF = 1: No multicollinearity (ideal).\n",
    "\n",
    "-1 < VIF < 5: Moderate multicollinearity (often acceptable).\n",
    "\n",
    "-5 <= VIF < 10: High multicollinearity (potentially problematic, common threshold range).\n",
    "\n",
    "-VIF >= 10: Very high multicollinearity (feature likely redundant, coefficients unstable in linear models).\n",
    "\n",
    "\n",
    "Feature Selection Use:\n",
    "\n",
    "-Used iteratively: Calculate VIF for all features, remove the one with the highest VIF if it exceeds a set threshold, repeat until all remaining features are below the threshold.\n",
    "\n",
    "Helps create a less redundant feature set, potentially improving model stability and interpretability.severe overfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Loading ---\n",
      "Loading data from: C:\\Users\\mason\\AVP\\BTCUSD.csv\n",
      "Raw data loaded. Shape: (60403, 9)\n",
      "Data prepared for feature engineering. Shape: (60403, 7)\n",
      "Columns: ['open', 'high', 'low', 'close', 'Volume BTC', 'Volume USD', 'timestamp']\n",
      "\n",
      "--- 2. Feature Engineering ---\n",
      "Starting feature calculation...\n",
      "Feature calculation finished. Returning 60403 rows with 115 columns.\n",
      "Feature calculation completed in 0.46 seconds.\n",
      "Total columns after feature engineering: 115\n",
      "Identified 107 potential features to analyze.\n",
      "\n",
      "--- 3. Cleaning Infinities (in Feature Columns) ---\n",
      "Replaced 0 infinite values with NaN.\n",
      "\n",
      "--- 4. Feature Selection: Variance Threshold (Threshold: 0.0003) ---\n",
      "Features before variance check: 107\n",
      "  Imputing 963 NaNs with medians temporarily for VarianceThreshold fitting.\n",
      "Removed 9 features with variance <= 0.0003.\n",
      "  Dropped by Variance Threshold: ['garman_klass_12h', 'lag_3h_price_return', 'lag_6h_price_return', 'log_return_1h', 'oc_change_pct', 'parkinson_3h', 'price_range_pct', 'price_return_1h', 'price_return_1h_sq']\n",
      "Features remaining after variance check: 98\n",
      "\n",
      "--- Feature Selection: Calculating VIF (Threshold: 6.9) ---\n",
      "Features before VIF check: 98\n",
      "  Warning: Found 938 NaNs. Imputing with column medians for VIF calculation ONLY.\n",
      "  Dropping 'hour_7' (VIF: 72638703667266.06)\n",
      "  Dropping 'ma_12h' (VIF: 404130.86)\n",
      "  Dropping 'ma_24h' (VIF: 374008.80)\n",
      "  Dropping 'ma_6h' (VIF: 131835.71)\n",
      "  Dropping 'day_3' (VIF: 94050.97)\n",
      "  Dropping 'ma_48h' (VIF: 72472.44)\n",
      "  Dropping 'macd' (VIF: 51231.16)\n",
      "  Dropping 'ma_3h' (VIF: 17664.20)\n",
      "  Dropping 'ma_72h' (VIF: 6159.60)\n",
      "  Dropping 'obv_ma_24h' (VIF: 1287.51)\n",
      "  Dropping 'ma_168h' (VIF: 979.96)\n",
      "  Dropping 'close_div_ma_168h' (VIF: 345.06)\n",
      "  Dropping 'bband_pctb_20h' (VIF: 86.51)\n",
      "  Dropping 'close_div_ma_48h' (VIF: 81.08)\n",
      "  Dropping 'atr_24h' (VIF: 54.95)\n",
      "  Dropping 'rolling_std_12h_sqrt' (VIF: 35.43)\n",
      "  Dropping 'atr_14h' (VIF: 27.79)\n",
      "  Dropping 'z_score_24h' (VIF: 24.68)\n",
      "  Dropping 'volume_ma_24h' (VIF: 19.08)\n",
      "  Dropping 'stoch_rsi_k' (VIF: 16.38)\n",
      "  Dropping 'ad_line' (VIF: 62.10)\n",
      "  Dropping 'plus_di_14h' (VIF: 44.53)\n",
      "  Dropping 'atr_14_div_atr_48' (VIF: 38.90)\n",
      "  Dropping 'minus_di_14h' (VIF: 36.51)\n",
      "  Dropping 'atr_48h' (VIF: 25.55)\n",
      "  Dropping 'rolling_std_72h' (VIF: 19.53)\n",
      "  Dropping 'obv' (VIF: 19.06)\n",
      "  Dropping 'ma12_div_ma48' (VIF: 20065.17)\n",
      "  Dropping 'close_div_ma_24h' (VIF: 5485.55)\n",
      "  Dropping 'ma24_div_ma168' (VIF: 93.64)\n",
      "  Dropping 'stoch_d' (VIF: 83.19)\n",
      "  Dropping 'rsi_14h' (VIF: 36.37)\n",
      "  Dropping 'stoch_k' (VIF: 23.29)\n",
      "  Dropping 'volume_ma_72h' (VIF: 17.29)\n",
      "  Dropping 'rolling_std_24h' (VIF: 13.89)\n",
      "  Dropping 'rolling_std_3h' (VIF: 10.26)\n",
      "  Dropping 'rolling_std_12h' (VIF: 9.83)\n",
      "  Dropping 'adx_14h' (VIF: 8.96)\n",
      "  Dropping 'stoch_rsi_d' (VIF: 8.54)\n",
      "  Dropping 'vwap_24h' (VIF: 8.09)\n",
      "  Max VIF (6.13) is below threshold 6.9. Stopping.\n",
      "Removed 40 features based on VIF.\n",
      "  Features Dropped by VIF: ['ad_line', 'adx_14h', 'atr_14_div_atr_48', 'atr_14h', 'atr_24h', 'atr_48h', 'bband_pctb_20h', 'close_div_ma_168h', 'close_div_ma_24h', 'close_div_ma_48h', 'day_3', 'hour_7', 'ma12_div_ma48', 'ma24_div_ma168', 'ma_12h', 'ma_168h', 'ma_24h', 'ma_3h', 'ma_48h', 'ma_6h', 'ma_72h', 'macd', 'minus_di_14h', 'obv', 'obv_ma_24h', 'plus_di_14h', 'rolling_std_12h', 'rolling_std_12h_sqrt', 'rolling_std_24h', 'rolling_std_3h', 'rolling_std_72h', 'rsi_14h', 'stoch_d', 'stoch_k', 'stoch_rsi_d', 'stoch_rsi_k', 'volume_ma_24h', 'volume_ma_72h', 'vwap_24h', 'z_score_24h']\n",
      "Features remaining after VIF check: 58\n",
      "--- VIF calculation finished. ---\n",
      "\n",
      "--- 6. Final Feature Selection Summary ---\n",
      "Total potential features identified:      107\n",
      "Features after Variance Threshold (0.0003): 98\n",
      "Features after VIF Threshold (6.9):      58\n",
      "\n",
      "Final list of selected feature names:\n",
      "  1. Volume BTC\n",
      "  2. Volume USD\n",
      "  3. bband_width_20h\n",
      "  4. cci_20h\n",
      "  5. close_pos_in_range\n",
      "  6. cmf_20h\n",
      "  7. day_0\n",
      "  8. day_1\n",
      "  9. day_2\n",
      "  10. day_4\n",
      "  11. day_5\n",
      "  12. day_6\n",
      "  13. hour_0\n",
      "  14. hour_1\n",
      "  15. hour_10\n",
      "  16. hour_11\n",
      "  17. hour_12\n",
      "  18. hour_13\n",
      "  19. hour_14\n",
      "  20. hour_15\n",
      "  21. hour_16\n",
      "  22. hour_17\n",
      "  23. hour_18\n",
      "  24. hour_19\n",
      "  25. hour_2\n",
      "  26. hour_20\n",
      "  27. hour_21\n",
      "  28. hour_22\n",
      "  29. hour_23\n",
      "  30. hour_3\n",
      "  31. hour_4\n",
      "  32. hour_5\n",
      "  33. hour_6\n",
      "  34. hour_8\n",
      "  35. hour_9\n",
      "  36. lag_12h_price_return\n",
      "  37. lag_12h_volume_return\n",
      "  38. lag_168h_price_return\n",
      "  39. lag_24h_price_return\n",
      "  40. lag_24h_volume_return\n",
      "  41. lag_3h_volume_return\n",
      "  42. lag_48h_price_return\n",
      "  43. lag_6h_volume_return\n",
      "  44. lag_72h_price_return\n",
      "  45. macd_hist\n",
      "  46. macd_signal\n",
      "  47. rolling_kurt_24h\n",
      "  48. rolling_skew_24h\n",
      "  49. rolling_std_168h\n",
      "  50. rolling_std_3h_sq\n",
      "  51. rolling_std_48h\n",
      "  52. rolling_std_6h\n",
      "  53. std12_div_std72\n",
      "  54. volume_btc_x_range\n",
      "  55. volume_div_ma_24h\n",
      "  56. volume_ma_12h\n",
      "  57. volume_ma_168h\n",
      "  58. volume_return_1h\n",
      "\n",
      "Total selected features: 58\n",
      "\n",
      "Feature selection script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "# Feature Engineering Imports\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Feature Selection Imports\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError # For handling VIF errors\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore') # General suppression\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = r'C:\\Users\\mason\\AVP\\BTCUSD.csv' # Use raw string for Windows paths\n",
    "SYMBOL_NAME = 'BTCUSD' # Define the symbol represented in the CSV\n",
    "\n",
    "# Feature Selection Thresholds\n",
    "VARIANCE_THRESHOLD = 0.0003  # Remove features with zero variance (constants)\n",
    "VIF_THRESHOLD = 6.9      # Remove features iteratively with VIF >= this value\n",
    "\n",
    "# Define columns that are NOT features to be selected (identifiers, raw data, target)\n",
    "# Make sure this list is comprehensive for your data\n",
    "NON_FEATURE_COLS = [\n",
    "    'timestamp', 'symbol', 'open', 'high', 'low', 'close', 'volume_btc', 'volume_usd',\n",
    "    'target', 'future_price', 'price_return_future', # Include potential target-related cols if they exist\n",
    "    'unix', 'date', 'symbol_csv', # From original loading if present before dropping\n",
    "    'volumefrom', 'volumeto', # Intermediate volume names if present\n",
    "    'tr' # Intermediate calculation like True Range if not dropped inside function\n",
    "]\n",
    "\n",
    "# --- Feature Engineering Function ---\n",
    "def calculate_advanced_features(df, symbol):\n",
    "    \"\"\"Calculate all the advanced features from OHLCV data\"\"\"\n",
    "    print(\"Starting feature calculation...\")\n",
    "    if df is None or len(df) < 3:\n",
    "        print(\"Input DataFrame is too small or None.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.copy()\n",
    "    df['symbol'] = symbol # Add symbol column needed by some logic/output structure\n",
    "\n",
    "    # Ensure timestamp is datetime and set as index temporarily\n",
    "    if 'timestamp' not in df.columns:\n",
    "        print(\"Error: 'timestamp' column not found.\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting timestamp column to datetime: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.sort_values('timestamp')\n",
    "    if df['timestamp'].isnull().any():\n",
    "         print(\"Warning: NaN values found in timestamp after conversion. Dropping rows.\")\n",
    "         df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "    df = df.set_index('timestamp', drop=False)\n",
    "\n",
    "    # Rename volume columns if they exist (handle potential missing cols)\n",
    "    if 'volumefrom' in df.columns:\n",
    "         df['volume_btc'] = df['volumefrom']\n",
    "    elif 'Volume BTC' in df.columns:\n",
    "         df['volume_btc'] = df['Volume BTC']\n",
    "    else:\n",
    "         # print(\"Warning: 'volumefrom' or 'Volume BTC' column not found. Volume features may fail.\")\n",
    "         df['volume_btc'] = 0 # Add dummy column\n",
    "\n",
    "    if 'volumeto' in df.columns:\n",
    "         df['volume_usd'] = df['volumeto']\n",
    "    elif 'Volume USD' in df.columns:\n",
    "         df['volume_usd'] = df['Volume USD']\n",
    "    else:\n",
    "         # print(\"Warning: 'volumeto' or 'Volume USD' column not found.\")\n",
    "         df['volume_usd'] = 0 # Add dummy column\n",
    "\n",
    "    # Basic Checks\n",
    "    required_cols = ['open', 'high', 'low', 'close', 'volume_btc']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: Required column '{col}' not found in DataFrame.\")\n",
    "            return pd.DataFrame()\n",
    "        # Ensure numeric types\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if df[required_cols].isnull().any().any():\n",
    "        print(f\"Warning: NaNs found in required OHLCV columns. Rows before drop: {len(df)}\")\n",
    "        df = df.dropna(subset=required_cols)\n",
    "        print(f\"Rows after dropping NaNs in OHLCV: {len(df)}\")\n",
    "        if df.empty: return pd.DataFrame()\n",
    "\n",
    "    # --- Time-Based Features ---\n",
    "    hour_of_day = df.index.hour\n",
    "    day_of_week = df.index.dayofweek\n",
    "    for hour in range(24): df[f'hour_{hour}'] = (hour_of_day == hour).astype(int)\n",
    "    for day in range(7): df[f'day_{day}'] = (day_of_week == day).astype(int)\n",
    "\n",
    "    # --- Basic Price & Volume Changes ---\n",
    "    df['price_return_1h'] = df['close'].pct_change()\n",
    "    df['oc_change_pct'] = (df['close'] - df['open']) / df['open']\n",
    "    df['price_range_pct'] = (df['high'] - df['low']) / df['low']\n",
    "    df['volume_return_1h'] = df['volume_btc'].pct_change()\n",
    "\n",
    "    # --- Moving Averages and Rolling Std ---\n",
    "    min_periods_base = 2\n",
    "    for hours in [3, 6, 12, 24, 48, 72, 168]:\n",
    "        if len(df) >= hours:\n",
    "            df[f'ma_{hours}h'] = df['close'].rolling(window=hours, min_periods=min_periods_base).mean()\n",
    "            df[f'rolling_std_{hours}h'] = df['close'].rolling(window=hours, min_periods=min_periods_base).std()\n",
    "        else: df[f'ma_{hours}h'], df[f'rolling_std_{hours}h'] = np.nan, np.nan\n",
    "\n",
    "    # --- Lagged Price & Volume Returns ---\n",
    "    for hours in [3, 6, 12, 24, 48, 72, 168]: df[f'lag_{hours}h_price_return'] = df['close'].pct_change(periods=hours)\n",
    "    for hours in [3, 6, 12, 24]: df[f'lag_{hours}h_volume_return'] = df['volume_btc'].pct_change(periods=hours)\n",
    "\n",
    "    # --- Volatility Measures ---\n",
    "    log_hl = np.log(df['high'].astype(float) / df['low'].astype(float))**2\n",
    "    log_co = np.log(df['close'].astype(float) / df['open'].astype(float))**2\n",
    "    df['garman_klass_12h'] = np.sqrt(0.5 * log_hl.rolling(12, min_periods=min(12, len(df))).sum() - (2*np.log(2)-1) * log_co.rolling(12, min_periods=min(12, len(df))).sum()) if len(df) >= 12 else np.nan\n",
    "    df['parkinson_3h'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(df['high'].astype(float) / df['low'].astype(float))**2).rolling(3, min_periods=min(3, len(df))).sum()) if len(df) >= 3 else np.nan\n",
    "    df['tr'] = np.maximum(df['high'] - df['low'], np.maximum(abs(df['high'] - df['close'].shift(1)), abs(df['low'] - df['close'].shift(1))))\n",
    "    for hours in [14, 24, 48]:\n",
    "        if len(df) >= hours: df[f'atr_{hours}h'] = df['tr'].rolling(hours, min_periods=hours).mean()\n",
    "        else: df[f'atr_{hours}h'] = np.nan\n",
    "\n",
    "    # --- Momentum Indicators (RSI, MACD) ---\n",
    "    if len(df) >= 14:\n",
    "        delta = df['close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=14).mean()\n",
    "        with np.errstate(divide='ignore', invalid='ignore'): rs = gain / loss\n",
    "        df['rsi_14h'] = (100 - (100 / (1 + rs))).replace([np.inf], 100).fillna(50)\n",
    "    else: df['rsi_14h'] = 50.0\n",
    "    min_ema_period = 26\n",
    "    if len(df) >= min_ema_period:\n",
    "        ema_12 = df['close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "        ema_26 = df['close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "        df['macd'] = ema_12 - ema_26\n",
    "        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "        df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    else: df['macd'], df['macd_signal'], df['macd_hist'] = np.nan, np.nan, np.nan\n",
    "\n",
    "    # --- Volume-Based Indicators ---\n",
    "    for hours in [12, 24, 72, 168]:\n",
    "        if len(df) >= hours: df[f'volume_ma_{hours}h'] = df['volume_btc'].rolling(window=hours, min_periods=min_periods_base).mean()\n",
    "        else: df[f'volume_ma_{hours}h'] = np.nan\n",
    "    with np.errstate(divide='ignore', invalid='ignore'): df['volume_div_ma_24h'] = df['volume_btc'] / df['volume_ma_24h']\n",
    "    obv = (np.sign(df['close'].diff()) * df['volume_btc']).fillna(0).cumsum(); df['obv'] = obv\n",
    "    if len(df) >= 24: df['obv_ma_24h'] = df['obv'].rolling(window=24, min_periods=min_periods_base).mean()\n",
    "    else: df['obv_ma_24h'] = np.nan\n",
    "\n",
    "    # --- Ratio Features ---\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['close_div_ma_24h'] = df['close'] / df['ma_24h']\n",
    "        df['close_div_ma_48h'] = df['close'] / df['ma_48h']\n",
    "        df['close_div_ma_168h'] = df['close'] / df['ma_168h']\n",
    "        df['ma12_div_ma48'] = df['ma_12h'] / df['ma_48h']\n",
    "        df['ma24_div_ma168'] = df['ma_24h'] / df['ma_168h']\n",
    "        df['std12_div_std72'] = df['rolling_std_12h'] / df['rolling_std_72h']\n",
    "        df['atr_14_div_atr_48'] = df['atr_14h'] / df['atr_48h']\n",
    "\n",
    "    # --- Normalized Price Position (Stochastic) ---\n",
    "    if len(df) >= 14:\n",
    "        low_14 = df['low'].rolling(window=14, min_periods=14).min()\n",
    "        high_14 = df['high'].rolling(window=14, min_periods=14).max()\n",
    "        range_14 = high_14 - low_14\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df['stoch_k'] = (100 * (df['close'] - low_14) / range_14).replace(np.inf, 50).fillna(50)\n",
    "        if len(df) >= 16: df['stoch_d'] = df['stoch_k'].rolling(window=3, min_periods=3).mean()\n",
    "        else: df['stoch_d'] = np.nan\n",
    "    else: df['stoch_k'], df['stoch_d'] = 50.0, np.nan\n",
    "    with np.errstate(divide='ignore', invalid='ignore'): df['z_score_24h'] = (df['close'] - df['ma_24h']) / df['rolling_std_24h']\n",
    "\n",
    "    # --- Higher-Order Statistics ---\n",
    "    if len(df) >= 24:\n",
    "        df['rolling_skew_24h'] = df['price_return_1h'].rolling(window=24, min_periods=24).skew()\n",
    "        df['rolling_kurt_24h'] = df['price_return_1h'].rolling(window=24, min_periods=24).kurt()\n",
    "    else: df['rolling_skew_24h'], df['rolling_kurt_24h'] = np.nan, np.nan\n",
    "\n",
    "    # --- Interaction & Non-linear ---\n",
    "    df['volume_btc_x_range'] = df['volume_btc'] * df['price_range_pct']\n",
    "    df['rolling_std_3h_sq'] = df['rolling_std_3h'] ** 2\n",
    "    df['price_return_1h_sq'] = df['price_return_1h'] ** 2\n",
    "    df['rolling_std_12h_sqrt'] = np.sqrt(df['rolling_std_12h'].abs())\n",
    "\n",
    "    # --- pandas_ta Features ---\n",
    "    # Use a temporary df for ta functions that might expect specific column names or modify the df inplace\n",
    "    ta_df = df.rename(columns={'volume_btc': 'volume'}, errors='ignore') # Rename for ta library if needed\n",
    "\n",
    "    # Check for required columns before calling ta functions\n",
    "    if all(c in ta_df.columns for c in ['high', 'low', 'close']):\n",
    "        # ADX/DMI\n",
    "        try: # Add try-except for robustness\n",
    "            adx_df = ta_df.ta.adx(length=14) # Check pandas_ta documentation for exact column names\n",
    "            if adx_df is not None and not adx_df.empty:\n",
    "                 # Adjust column names based on your pandas_ta version output\n",
    "                 df['adx_14h'] = adx_df.get(f'ADX_14', np.nan)\n",
    "                 df['plus_di_14h'] = adx_df.get(f'DMP_14', np.nan)\n",
    "                 df['minus_di_14h'] = adx_df.get(f'DMN_14', np.nan)\n",
    "            else: df['adx_14h'], df['plus_di_14h'], df['minus_di_14h'] = np.nan, np.nan, np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating ADX: {e}\")\n",
    "            df['adx_14h'], df['plus_di_14h'], df['minus_di_14h'] = np.nan, np.nan, np.nan\n",
    "\n",
    "        # Accumulation/Distribution Line (requires volume)\n",
    "        if 'volume' in ta_df.columns:\n",
    "             try: df['ad_line'] = ta_df.ta.ad()\n",
    "             except Exception as e: print(f\"Warning: Error calculating AD Line: {e}\"); df['ad_line'] = np.nan\n",
    "        else: df['ad_line'] = np.nan\n",
    "\n",
    "        # Chaikin Money Flow (requires volume)\n",
    "        if 'volume' in ta_df.columns:\n",
    "             try: df['cmf_20h'] = ta_df.ta.cmf(length=20)\n",
    "             except Exception as e: print(f\"Warning: Error calculating CMF: {e}\"); df['cmf_20h'] = np.nan\n",
    "        else: df['cmf_20h'] = np.nan\n",
    "\n",
    "        # Commodity Channel Index\n",
    "        try: df['cci_20h'] = ta_df.ta.cci(length=20)\n",
    "        except Exception as e: print(f\"Warning: Error calculating CCI: {e}\"); df['cci_20h'] = np.nan\n",
    "\n",
    "        # Bollinger Bands\n",
    "        try:\n",
    "            bbands_df = ta_df.ta.bbands(length=20, std=2)\n",
    "            if bbands_df is not None and not bbands_df.empty:\n",
    "                # Adjust column names based on your pandas_ta version output (e.g., BBB_20_2.0, BBP_20_2.0)\n",
    "                df['bband_width_20h'] = bbands_df.get(f'BBB_20_2.0', np.nan) # Bandwidth\n",
    "                df['bband_pctb_20h'] = bbands_df.get(f'BBP_20_2.0', np.nan) # %B\n",
    "            else: df['bband_width_20h'], df['bband_pctb_20h'] = np.nan, np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating Bollinger Bands: {e}\")\n",
    "            df['bband_width_20h'], df['bband_pctb_20h'] = np.nan, np.nan\n",
    "    else:\n",
    "        print(\"Warning: Missing high, low, or close columns. Skipping some pandas_ta features.\")\n",
    "        # Add NaN columns explicitly if base cols are missing\n",
    "        df['adx_14h'], df['plus_di_14h'], df['minus_di_14h'] = np.nan, np.nan, np.nan\n",
    "        df['ad_line'], df['cmf_20h'], df['cci_20h'] = np.nan, np.nan, np.nan\n",
    "        df['bband_width_20h'], df['bband_pctb_20h'] = np.nan, np.nan\n",
    "\n",
    "\n",
    "    # --- Position in Range ---\n",
    "    range_hl = df['high'] - df['low']\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['close_pos_in_range'] = ((df['close'] - df['low']) / range_hl).fillna(0.5).replace([np.inf, -np.inf], 0.5)\n",
    "\n",
    "    # --- Additional Features ---\n",
    "    df['log_return_1h'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    # VWAP (24h)\n",
    "    if 'volume_btc' in df.columns and len(df) >= 24:\n",
    "        numerator = (df['close'] * df['volume_btc']).rolling(window=24, min_periods=24).sum()\n",
    "        denominator = df['volume_btc'].rolling(window=24, min_periods=24).sum()\n",
    "        with np.errstate(divide='ignore', invalid='ignore'): df['vwap_24h'] = numerator / denominator\n",
    "        df['vwap_24h'] = df['vwap_24h'].fillna(method='ffill') # Optional: forward fill VWAP NaNs\n",
    "    else: df['vwap_24h'] = np.nan\n",
    "    # Stochastic RSI using pandas_ta\n",
    "    if 'close' in ta_df.columns:\n",
    "        try:\n",
    "            stochrsi_df = ta_df.ta.stochrsi(length=14)\n",
    "            if stochrsi_df is not None and not stochrsi_df.empty:\n",
    "                # Adjust column names based on pandas_ta version output\n",
    "                k_col = next((col for col in stochrsi_df.columns if 'STOCHRSIk' in col), None)\n",
    "                d_col = next((col for col in stochrsi_df.columns if 'STOCHRSId' in col), None)\n",
    "                df['stoch_rsi_k'] = stochrsi_df[k_col] if k_col else np.nan\n",
    "                df['stoch_rsi_d'] = stochrsi_df[d_col] if d_col else np.nan\n",
    "            else: df['stoch_rsi_k'], df['stoch_rsi_d'] = np.nan, np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating StochRSI: {e}\")\n",
    "            df['stoch_rsi_k'], df['stoch_rsi_d'] = np.nan, np.nan\n",
    "    else: df['stoch_rsi_k'], df['stoch_rsi_d'] = np.nan, np.nan\n",
    "\n",
    "\n",
    "    # --- Final Cleanup ---\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan) # Final check for inf\n",
    "\n",
    "    # Remove intermediate features if desired (e.g., 'tr' was used for ATR)\n",
    "    df = df.drop(columns=['tr'], errors='ignore')\n",
    "\n",
    "    print(f\"Feature calculation finished. Returning {len(df)} rows with {len(df.columns)} columns.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Helper Function for VIF Calculation ---\n",
    "def calculate_vif(df_features, vif_threshold=10.0, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculates VIF for a DataFrame of features and iteratively removes\n",
    "    features with VIF above the threshold.\n",
    "\n",
    "    Args:\n",
    "        df_features (pd.DataFrame): DataFrame containing ONLY the numeric features to check.\n",
    "        vif_threshold (float): The threshold above which features will be removed.\n",
    "        verbose (bool): If True, print messages about dropped features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of feature names (strings) that remain after VIF filtering.\n",
    "    \"\"\"\n",
    "    if df_features.empty:\n",
    "        print(\"VIF calculation skipped: Input DataFrame is empty.\")\n",
    "        return []\n",
    "\n",
    "    if verbose: print(f\"\\n--- Feature Selection: Calculating VIF (Threshold: {vif_threshold}) ---\")\n",
    "    features = df_features.copy()\n",
    "    original_feature_count = features.shape[1]\n",
    "    if verbose: print(f\"Features before VIF check: {original_feature_count}\")\n",
    "\n",
    "    # VIF cannot handle NaN or Inf values. Impute temporarily for calculation.\n",
    "    num_nans_before = features.isnull().sum().sum()\n",
    "    if num_nans_before > 0:\n",
    "        if verbose: print(f\"  Warning: Found {num_nans_before} NaNs. Imputing with column medians for VIF calculation ONLY.\")\n",
    "        medians = features.median() # Calculate medians once\n",
    "        features = features.fillna(medians)\n",
    "        # Verify imputation worked\n",
    "        num_nans_after = features.isnull().sum().sum()\n",
    "        if num_nans_after > 0:\n",
    "             print(f\"  ERROR: {num_nans_after} NaNs remain after median imputation. Dropping columns with all NaNs before VIF.\")\n",
    "             cols_all_nan = features.columns[features.isnull().all()].tolist()\n",
    "             print(f\"  Dropping: {cols_all_nan}\")\n",
    "             features = features.dropna(axis=1, how='all')\n",
    "             if features.empty:\n",
    "                  print(\"  ERROR: DataFrame empty after dropping all-NaN columns. VIF calculation aborted.\")\n",
    "                  return [] # Return empty list\n",
    "\n",
    "    # Check for infinities (should have been handled earlier, but robust check)\n",
    "    num_infs = np.isinf(features.values).sum()\n",
    "    if num_infs > 0:\n",
    "        print(f\"  ERROR: Found {num_infs} infinite values even after initial cleaning. Cannot calculate VIF. Aborting.\")\n",
    "        # Return original column names from input df_features as fallback\n",
    "        return df_features.columns.tolist()\n",
    "\n",
    "    # Check for constant columns after imputation (VIF calculation will fail)\n",
    "    constant_cols = features.columns[features.nunique() <= 1].tolist()\n",
    "    if constant_cols:\n",
    "        if verbose: print(f\"  Warning: Removing constant columns found after imputation before VIF: {constant_cols}\")\n",
    "        features = features.drop(columns=constant_cols)\n",
    "        if features.empty:\n",
    "            print(\"  ERROR: DataFrame empty after dropping constant columns post-imputation. VIF calculation aborted.\")\n",
    "            return [] # Return empty list\n",
    "\n",
    "    # Initial list of features to check\n",
    "    kept_features = features.columns.tolist()\n",
    "    dropped_features_vif = [] # Keep track of dropped features\n",
    "\n",
    "    # Iterative VIF calculation\n",
    "    while len(kept_features) > 1: # Need at least 2 features for VIF\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"feature\"] = kept_features\n",
    "        try:\n",
    "            # Calculate VIF - ensure features[kept_features] is used\n",
    "            vif_values = [variance_inflation_factor(features[kept_features].values, i)\n",
    "                          for i in range(len(kept_features))]\n",
    "            vif_data[\"VIF\"] = vif_values\n",
    "        except PerfectSeparationError:\n",
    "            # Handle perfect multicollinearity error\n",
    "            print(\"  Error: Perfect separation detected during VIF calculation (implies perfect linear dependency).\")\n",
    "            # Option 1: Stop VIF here\n",
    "            # print(\"  Stopping VIF calculation prematurely.\")\n",
    "            # break\n",
    "            # Option 2: Try to identify and remove one of the likely culprits (more complex)\n",
    "            # For simplicity, we stop here. Manual inspection might be needed.\n",
    "            print(\"  Stopping VIF calculation. Manual inspection of remaining features recommended.\")\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            # Catch errors like \"contains NaNs\" if imputation failed somehow\n",
    "             print(f\"  ValueError during VIF calculation: {ve}. Check data for unexpected NaNs/Infs.\")\n",
    "             break\n",
    "        except Exception as e:\n",
    "            # Catch other potential errors\n",
    "            print(f\"  Unexpected error calculating VIF: {e}\")\n",
    "            print(\"  Stopping VIF calculation.\")\n",
    "            break\n",
    "\n",
    "        max_vif = vif_data['VIF'].max()\n",
    "\n",
    "        # Check for NaN/Inf in VIF results (can happen with near-perfect multicollinearity)\n",
    "        is_nan_inf = vif_data['VIF'].isna() | np.isinf(vif_data['VIF'])\n",
    "        if is_nan_inf.any():\n",
    "             nan_inf_vif_features = vif_data.loc[is_nan_inf, 'feature'].tolist()\n",
    "             if verbose: print(f\"  Warning: Found NaN/Inf VIF for features: {nan_inf_vif_features}. Indicates extreme multicollinearity.\")\n",
    "             # Drop the first feature found with NaN/Inf VIF in this iteration\n",
    "             feature_to_drop_inf = nan_inf_vif_features[0]\n",
    "             if verbose: print(f\"  Dropping feature '{feature_to_drop_inf}' due to NaN/Inf VIF.\")\n",
    "             kept_features.remove(feature_to_drop_inf)\n",
    "             dropped_features_vif.append(feature_to_drop_inf)\n",
    "             continue # Recalculate VIF with the reduced set\n",
    "\n",
    "        # Check if the highest VIF is below the threshold\n",
    "        if max_vif < vif_threshold:\n",
    "            if verbose: print(f\"  Max VIF ({max_vif:.2f}) is below threshold {vif_threshold}. Stopping.\")\n",
    "            break\n",
    "        else:\n",
    "            # Find and drop the feature with the highest VIF\n",
    "            feature_to_drop = vif_data.sort_values('VIF', ascending=False)['feature'].iloc[0]\n",
    "            if verbose: print(f\"  Dropping '{feature_to_drop}' (VIF: {max_vif:.2f})\")\n",
    "            kept_features.remove(feature_to_drop)\n",
    "            dropped_features_vif.append(feature_to_drop)\n",
    "\n",
    "    # End of VIF loop\n",
    "    if verbose:\n",
    "        print(f\"Removed {len(dropped_features_vif)} features based on VIF.\")\n",
    "        if dropped_features_vif:\n",
    "            # Sort for consistent output\n",
    "            print(f\"  Features Dropped by VIF: {sorted(list(dropped_features_vif))}\")\n",
    "        print(f\"Features remaining after VIF check: {len(kept_features)}\")\n",
    "        print(f\"--- VIF calculation finished. ---\")\n",
    "\n",
    "    # Return the final list of features that passed the VIF check\n",
    "    # These names correspond to columns in the original df_features input\n",
    "    final_kept_feature_names = [col for col in df_features.columns if col in kept_features]\n",
    "    return final_kept_feature_names\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"--- 1. Data Loading ---\")\n",
    "    try:\n",
    "        print(f\"Loading data from: {CSV_FILE_PATH}\")\n",
    "        # Adjust column names based on your actual CSV header\n",
    "        col_names = ['unix', 'date', 'symbol_csv', 'open', 'high', 'low', 'close', 'Volume BTC', 'Volume USD']\n",
    "        df_raw = pd.read_csv(CSV_FILE_PATH, header=0, names=col_names) # Assumes header is present, uses provided names\n",
    "        print(f\"Raw data loaded. Shape: {df_raw.shape}\")\n",
    "\n",
    "        # Basic preprocessing: Use 'date' column, drop others\n",
    "        df_raw['timestamp'] = pd.to_datetime(df_raw['date'])\n",
    "        df_raw = df_raw.drop(['unix', 'date', 'symbol_csv'], axis=1) # Drop original time/symbol cols\n",
    "        df_raw = df_raw.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "        if df_raw.empty:\n",
    "            print(\"DataFrame is empty after loading/initial processing. Exiting.\")\n",
    "            exit()\n",
    "        print(f\"Data prepared for feature engineering. Shape: {df_raw.shape}\")\n",
    "        print(f\"Columns: {df_raw.columns.tolist()}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {CSV_FILE_PATH}\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing CSV: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n--- 2. Feature Engineering ---\")\n",
    "    feature_calc_start = time.time()\n",
    "    df_full_features = calculate_advanced_features(df_raw, symbol=SYMBOL_NAME)\n",
    "    feature_calc_end = time.time()\n",
    "\n",
    "    if df_full_features.empty:\n",
    "        print(\"Feature calculation failed or resulted in empty DataFrame. Exiting.\")\n",
    "        exit()\n",
    "    print(f\"Feature calculation completed in {feature_calc_end - feature_calc_start:.2f} seconds.\")\n",
    "    print(f\"Total columns after feature engineering: {len(df_full_features.columns)}\")\n",
    "\n",
    "    # Identify potential features by excluding NON_FEATURE_COLS\n",
    "    all_potential_features = [col for col in df_full_features.columns if col not in NON_FEATURE_COLS]\n",
    "    print(f\"Identified {len(all_potential_features)} potential features to analyze.\")\n",
    "\n",
    "    # Create DataFrame with only potential features for selection steps\n",
    "    df_features_only = df_full_features[all_potential_features].copy()\n",
    "\n",
    "    print(\"\\n--- 3. Cleaning Infinities (in Feature Columns) ---\")\n",
    "    infinite_before = np.isinf(df_features_only.values).sum()\n",
    "    df_features_only = df_features_only.replace([np.inf, -np.inf], np.nan)\n",
    "    print(f\"Replaced {infinite_before - np.isinf(df_features_only.values).sum()} infinite values with NaN.\")\n",
    "\n",
    "    # --- 4. Feature Selection: Variance Threshold ---\n",
    "    print(f\"\\n--- 4. Feature Selection: Variance Threshold (Threshold: {VARIANCE_THRESHOLD}) ---\")\n",
    "    features_before_variance = df_features_only.columns.tolist()\n",
    "    print(f\"Features before variance check: {len(features_before_variance)}\")\n",
    "\n",
    "    # VarianceThreshold needs non-NaN data to fit. Use median imputation temporarily FOR FITTING ONLY.\n",
    "    # Create a temporary imputed version for fitting the selector\n",
    "    df_temp_imputed_var = df_features_only.copy()\n",
    "    num_nans_variance = df_temp_imputed_var.isnull().sum().sum()\n",
    "    if num_nans_variance > 0:\n",
    "        print(f\"  Imputing {num_nans_variance} NaNs with medians temporarily for VarianceThreshold fitting.\")\n",
    "        df_temp_imputed_var = df_temp_imputed_var.fillna(df_temp_imputed_var.median())\n",
    "\n",
    "    try:\n",
    "        selector = VarianceThreshold(threshold=VARIANCE_THRESHOLD)\n",
    "        # Fit on the imputed data\n",
    "        selector.fit(df_temp_imputed_var)\n",
    "        # Get the mask and apply to the *original* feature list (before imputation)\n",
    "        features_after_variance = df_features_only.columns[selector.get_support()].tolist()\n",
    "        dropped_variance = set(features_before_variance) - set(features_after_variance)\n",
    "        print(f\"Removed {len(dropped_variance)} features with variance <= {VARIANCE_THRESHOLD}.\")\n",
    "        if dropped_variance:\n",
    "             # Sort for consistent output\n",
    "             print(f\"  Dropped by Variance Threshold: {sorted(list(dropped_variance))}\")\n",
    "    except Exception as e_var:\n",
    "        print(f\"Could not perform variance thresholding: {e_var}\")\n",
    "        print(\"Skipping variance filtering.\")\n",
    "        features_after_variance = features_before_variance # Keep all features if error\n",
    "\n",
    "    print(f\"Features remaining after variance check: {len(features_after_variance)}\")\n",
    "\n",
    "    # Update the DataFrame to contain only features that passed variance check\n",
    "    df_features_selected = df_features_only[features_after_variance].copy()\n",
    "\n",
    "\n",
    "    # --- 5. Feature Selection: VIF Threshold ---\n",
    "    # Pass the DataFrame containing only features that passed the variance check\n",
    "    features_after_vif = calculate_vif(\n",
    "        df_features_selected, # Pass the dataframe with features selected so far\n",
    "        vif_threshold=VIF_THRESHOLD,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- 6. Final Selected Features ---\n",
    "    print(f\"\\n--- 6. Final Feature Selection Summary ---\")\n",
    "    print(f\"Total potential features identified:      {len(all_potential_features)}\")\n",
    "    print(f\"Features after Variance Threshold ({VARIANCE_THRESHOLD}): {len(features_after_variance)}\")\n",
    "    print(f\"Features after VIF Threshold ({VIF_THRESHOLD}):      {len(features_after_vif)}\")\n",
    "    print(\"\\nFinal list of selected feature names:\")\n",
    "    # Print the list nicely\n",
    "    if features_after_vif:\n",
    "        for i, feature in enumerate(sorted(features_after_vif)): # Sort alphabetically for readability\n",
    "            print(f\"  {i+1}. {feature}\")\n",
    "    else:\n",
    "        print(\"  No features remained after filtering.\")\n",
    "\n",
    "    print(f\"\\nTotal selected features: {len(features_after_vif)}\")\n",
    "    print(\"\\nFeature selection script finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's a creative and logical extension to address the \"Delayed Reaction\" problem! Adding an event-based trigger (large price move) alongside the scheduled daily VIF recalculation is definitely possible and aims to make the feature selection more responsive during potentially regime-shifting moments.\n",
    "\n",
    "Let's analyze this hybrid approach:\n",
    "\n",
    "Concept:\n",
    "\n",
    "Baseline: Recalculate VIF once a day using a long lookback window (e.g., past 24 hours or several days of minute data) to determine the standard active feature set.\n",
    "\n",
    "Event Trigger: Monitor the price change over a short, recent period (e.g., last 5-15 minutes, or since the last model run). If the absolute percentage change exceeds a threshold (e.g., +/- 4%), immediately trigger another VIF recalculation using the standard long lookback window.\n",
    "\n",
    "Feature Set Update: Whenever VIF is recalculated (either scheduled or event-triggered), update the \"currently active\" feature list used by the frequently running classification model.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Faster Adaptation (Potential): In theory, this allows the system to reassess feature multicollinearity much faster during extreme moves than waiting for the next daily cycle. If the flash crash/pump does significantly alter the correlation structure, the model might benefit from an updated feature set sooner.\n",
    "\n",
    "Targeted Recalculation: Avoids constant VIF recalculation (like every minute) but adds computation only when potentially necessary (during high volatility).\n",
    "\n",
    "Cons & Considerations:\n",
    "\n",
    "Correlation Calculation Lag: This is still the biggest challenge. Correlation (and therefore VIF) is calculated over a window. When a +/- 4% move happens very quickly, the bulk of the data within your chosen VIF calculation window (e.g., the last 24 hours) still represents the previous market regime. The VIF calculation triggered immediately might not show a drastically different result until the new regime dominates a larger portion of that window. The change in VIF might lag the price event considerably.\n",
    "\n",
    "VIF Window Choice: Which window do you use for the event-triggered VIF?\n",
    "\n",
    "Using the standard long window (e.g., 24h): More stable VIF calculation, but slow to reflect the immediate change (as mentioned above).\n",
    "\n",
    "Using a very short window around the event: VIF calculation becomes highly unstable and unreliable. Not recommended.\n",
    "\n",
    "The most practical approach is likely sticking to the standard long window even for event triggers, accepting the inherent lag.\n",
    "\n",
    "Is Price Change the Right Trigger? Does a 4% move reliably indicate a change in correlation structure? Sometimes yes, sometimes no. It definitely indicates high volatility, but features might maintain their relationships. You might trigger recalculations that don't lead to significant changes in the selected feature set.\n",
    "\n",
    "Whipsaws and Noise: In choppy markets, you might get multiple +/- 4% moves triggering frequent VIF recalculations, increasing computational load without necessarily providing a consistently better feature set if the underlying structure isn't fundamentally shifting back and forth that quickly.\n",
    "\n",
    "Increased Complexity: Managing both scheduled and event-based triggers adds complexity to your system architecture and testing.\n",
    "\n",
    "Downstream Model Impact: Frequent changes to the feature set (even if only hourly + occasional events) might require the downstream classification model to be retrained more often or require careful handling to ensure it can cope with varying input features.\n",
    "\n",
    "Alternative/Refinement:\n",
    "\n",
    "Trigger on Volatility Increase: Instead of price change, trigger the VIF recalculation if a volatility measure (e.g., rolling ATR over the VIF window, or short-term vs long-term volatility ratio) crosses a significant threshold. This might be slightly more indicative of a potential regime change than price alone, but still suffers from the lag issue.\n",
    "\n",
    "More Frequent Scheduled Updates: Simply increasing the scheduled VIF update frequency (e.g., from daily to every 4 hours or hourly) might be a simpler and sufficiently effective way to reduce the delay without the complexities of event triggers.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Adding an event-based trigger for VIF recalculation based on large price moves is an interesting idea and technically feasible. It could potentially reduce the reaction delay during major market shifts compared to only daily updates.\n",
    "\n",
    "However, be aware of the significant challenge posed by the lag inherent in correlation/VIF calculations over a window. The immediate trigger might not yield an immediately different feature set. You also introduce complexity and potential noise triggers.\n",
    "\n",
    "Recommendation:\n",
    "\n",
    "Start Simpler: Implement the periodic VIF update first (e.g., daily or every few hours).\n",
    "\n",
    "Monitor: Observe how stable the selected feature set is over time. Does it change significantly between updates?\n",
    "\n",
    "Consider the Trade-off: If you observe that significant market events often seem to precede changes in the optimal feature set and the delay is hurting performance, then consider experimenting with event-based triggers.\n",
    "\n",
    "Test Thoroughly: If you implement event triggers, rigorously test the impact on performance, computational load, and overall system stability, paying close attention to the actual change (or lack thereof) in the selected features immediately following events.\n",
    "\n",
    "It might turn out that more frequent scheduled updates (e.g., hourly) provide a better balance of adaptivity, stability, and complexity than adding event-based triggers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post VIF Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 7. Advanced Feature Engineering (Post-Initial VIF) ---\n",
      "Starting with 58 features selected by initial VIF.\n",
      "\n",
      "  --- A. Applying Univariate Transformations ---\n",
      "  Applying log1p to 9 features...\n",
      "  Applying sqrt to 5 features...\n",
      "  Applying square to 10 features...\n",
      "\n",
      "  --- B. Creating Interaction Terms (Multiplication) ---\n",
      "  Creating 188 interaction features...\n",
      "  Successfully created 188 interaction features.\n",
      "\n",
      "  --- C. Creating Interaction Terms (Division - Selective) ---\n",
      "  Creating 1 ratio features...\n",
      "\n",
      "  --- D. Cleaning Engineered Features ---\n",
      "Total features after advanced engineering: 271\n",
      "\n",
      "--- 8. Running VIF on Expanded Feature Set ---\n",
      "\n",
      "--- Feature Selection: Calculating VIF (Threshold: 6.9) ---\n",
      "Features before VIF check: 271\n",
      "  Warning: Found 8602 NaNs. Imputing with column medians for VIF calculation ONLY.\n",
      "  Dropping 'volume_return_1h_x_rolling_std_48h' (VIF: 404620.59)\n",
      "  Dropping 'macd_signal_x_volume_return_1h' (VIF: 211199.78)\n",
      "  Dropping 'lag_48h_price_return_x_volume_return_1h' (VIF: 102324.20)\n",
      "  Dropping 'volume_return_1h_sq' (VIF: 78528.17)\n",
      "  Dropping 'volume_return_1h_x_rolling_std_168h' (VIF: 59399.18)\n",
      "  Dropping 'lag_72h_price_return_x_volume_return_1h' (VIF: 41367.88)\n",
      "  Dropping 'volume_return_1h_x_bband_width_20h' (VIF: 32665.66)\n",
      "  Dropping 'lag_168h_price_return_x_volume_return_1h' (VIF: 21942.96)\n",
      "  Dropping 'lag_6h_volume_return_x_rolling_std_48h' (VIF: 16193.96)\n",
      "  Dropping 'lag_12h_volume_return_x_rolling_std_48h' (VIF: 13149.26)\n",
      "  Dropping 'lag_3h_volume_return_x_rolling_std_48h' (VIF: 11874.49)\n",
      "  Dropping 'volume_return_1h_x_rolling_std_6h' (VIF: 9517.35)\n",
      "  Dropping 'volume_return_1h_x_std12_div_std72' (VIF: 8361.00)\n",
      "  Dropping 'lag_3h_volume_return_x_rolling_std_168h' (VIF: 4202.18)\n",
      "  Dropping 'lag_6h_volume_return_x_rolling_std_168h' (VIF: 4140.54)\n",
      "  Dropping 'lag_12h_volume_return_x_rolling_std_168h' (VIF: 3688.98)\n",
      "  Dropping 'macd_signal_x_lag_3h_volume_return' (VIF: 3442.17)\n",
      "  Dropping 'lag_12h_volume_return_x_bband_width_20h' (VIF: 3215.48)\n",
      "  Dropping 'rolling_std_168h_log1p' (VIF: 3156.73)\n",
      "  Dropping 'bband_width_20h_sqrt' (VIF: 15963.25)\n",
      "  Dropping 'lag_48h_price_return_x_lag_3h_volume_return' (VIF: 2773.80)\n",
      "  Dropping 'macd_hist_x_lag_12h_volume_return' (VIF: 2693.97)\n",
      "  Dropping 'macd_hist_x_lag_6h_volume_return' (VIF: 2594.53)\n",
      "  Dropping 'lag_3h_volume_return' (VIF: 2541.81)\n",
      "  Dropping 'lag_12h_price_return_x_volume_return_1h' (VIF: 2127.71)\n",
      "  Dropping 'lag_6h_volume_return_x_bband_width_20h' (VIF: 1844.85)\n",
      "  Dropping 'macd_signal_x_lag_6h_volume_return' (VIF: 1700.96)\n",
      "  Dropping 'rolling_std_48h_log1p' (VIF: 1497.23)\n",
      "  Dropping 'lag_168h_price_return_x_lag_6h_volume_return' (VIF: 1459.85)\n",
      "  Dropping 'lag_168h_price_return_x_lag_12h_volume_return' (VIF: 1324.18)\n",
      "  Dropping 'macd_hist_x_volume_return_1h' (VIF: 1293.36)\n",
      "  Dropping 'lag_3h_volume_return_x_bband_width_20h' (VIF: 954.81)\n",
      "  Dropping 'rolling_std_6h_log1p' (VIF: 794.20)\n",
      "  Dropping 'lag_168h_price_return_x_lag_3h_volume_return' (VIF: 755.22)\n",
      "  Dropping 'Volume BTC_log1p' (VIF: 752.67)\n",
      "  Dropping 'lag_12h_volume_return_x_rolling_std_6h' (VIF: 717.26)\n",
      "  Dropping 'lag_6h_volume_return_x_rolling_std_6h' (VIF: 696.36)\n",
      "  Dropping 'lag_12h_volume_return_x_std12_div_std72' (VIF: 508.86)\n",
      "  Dropping 'macd_hist_x_lag_3h_volume_return' (VIF: 432.61)\n",
      "  Dropping 'lag_12h_price_return_x_lag_12h_volume_return' (VIF: 406.68)\n",
      "  Dropping 'rolling_std_48h_sqrt' (VIF: 379.80)\n",
      "  Dropping 'lag_6h_volume_return' (VIF: 364.92)\n",
      "  Dropping 'volume_ma_12h_log1p' (VIF: 361.34)\n",
      "  Dropping 'lag_3h_volume_return_x_std12_div_std72' (VIF: 308.28)\n",
      "  Dropping 'lag_24h_volume_return' (VIF: 298.66)\n",
      "  Dropping 'lag_24h_volume_return_x_rolling_std_48h' (VIF: 264.86)\n",
      "  Dropping 'macd_signal_x_lag_12h_volume_return' (VIF: 256.97)\n",
      "  Dropping 'lag_48h_price_return_x_lag_6h_volume_return' (VIF: 233.08)\n",
      "  Dropping 'rolling_std_168h_sqrt' (VIF: 202.52)\n",
      "  Dropping 'cci_20h_x_volume_return_1h' (VIF: 156.38)\n",
      "  Dropping 'lag_12h_price_return_x_lag_3h_volume_return' (VIF: 148.14)\n",
      "  Dropping 'rolling_std_6h_sqrt' (VIF: 139.99)\n",
      "  Dropping 'lag_48h_price_return_x_lag_12h_volume_return' (VIF: 112.16)\n",
      "  Dropping 'bband_width_20h_log1p' (VIF: 106.75)\n",
      "  Dropping 'volume_ma_168h_log1p' (VIF: 99.71)\n",
      "  Dropping 'lag_24h_price_return_x_volume_ma_12h' (VIF: 97.83)\n",
      "  Dropping 'lag_24h_volume_return_x_bband_width_20h' (VIF: 94.86)\n",
      "  Dropping 'lag_48h_price_return_x_volume_ma_12h' (VIF: 88.00)\n",
      "  Dropping 'cci_20h_x_lag_12h_volume_return' (VIF: 80.29)\n",
      "  Dropping 'volume_ma_12h_x_rolling_std_48h' (VIF: 78.87)\n",
      "  Dropping 'lag_12h_price_return_x_lag_24h_volume_return' (VIF: 71.70)\n",
      "  Dropping 'lag_24h_price_return_x_lag_3h_volume_return' (VIF: 70.60)\n",
      "  Dropping 'lag_12h_price_return_x_volume_ma_12h' (VIF: 63.35)\n",
      "  Dropping 'lag_48h_price_return_x_bband_width_20h' (VIF: 62.72)\n",
      "  Dropping 'lag_24h_volume_return_x_rolling_std_6h' (VIF: 59.18)\n",
      "  Dropping 'lag_24h_price_return_x_volume_return_1h' (VIF: 56.08)\n",
      "  Dropping 'lag_24h_price_return_x_Volume BTC' (VIF: 50.76)\n",
      "  Dropping 'lag_12h_price_return' (VIF: 49.05)\n",
      "  Dropping 'lag_48h_price_return_x_rolling_std_48h' (VIF: 46.67)\n",
      "  Dropping 'volume_ma_168h' (VIF: 46.17)\n",
      "  Dropping 'lag_24h_price_return_x_rolling_std_48h' (VIF: 44.88)\n",
      "  Dropping 'Volume USD_log1p' (VIF: 43.65)\n",
      "  Dropping 'lag_72h_price_return_x_volume_ma_12h' (VIF: 43.36)\n",
      "  Dropping 'lag_12h_price_return_x_lag_6h_volume_return' (VIF: 42.43)\n",
      "  Dropping 'lag_48h_price_return_x_Volume BTC' (VIF: 39.41)\n",
      "  Dropping 'lag_24h_price_return' (VIF: 35.87)\n",
      "  Dropping 'volume_ma_12h_x_rolling_std_168h' (VIF: 34.75)\n",
      "  Dropping 'lag_24h_price_return_x_bband_width_20h' (VIF: 34.66)\n",
      "  Dropping 'lag_12h_price_return_x_rolling_std_6h' (VIF: 34.53)\n",
      "  Dropping 'lag_72h_price_return_x_rolling_std_48h' (VIF: 32.35)\n",
      "  Dropping 'lag_48h_price_return' (VIF: 31.48)\n",
      "  Dropping 'lag_168h_price_return_x_lag_24h_volume_return' (VIF: 31.24)\n",
      "  Dropping 'Volume BTC_x_rolling_std_48h' (VIF: 30.57)\n",
      "  Dropping 'lag_12h_price_return_x_rolling_std_48h' (VIF: 30.15)\n",
      "  Dropping 'lag_12h_volume_return_x_rolling_kurt_24h' (VIF: 29.90)\n",
      "  Dropping 'cci_20h_x_bband_width_20h' (VIF: 28.45)\n",
      "  Dropping 'lag_12h_price_return_x_std12_div_std72' (VIF: 27.83)\n",
      "  Dropping 'lag_48h_price_return_x_rolling_std_6h' (VIF: 27.40)\n",
      "  Dropping 'lag_3h_volume_return_x_rolling_std_6h' (VIF: 27.38)\n",
      "  Dropping 'lag_72h_price_return_x_bband_width_20h' (VIF: 25.71)\n",
      "  Dropping 'macd_hist' (VIF: 25.41)\n",
      "  Dropping 'lag_12h_price_return_x_Volume BTC' (VIF: 25.36)\n",
      "  Dropping 'cci_20h_x_lag_6h_volume_return' (VIF: 24.64)\n",
      "  Dropping 'volume_ma_12h' (VIF: 24.54)\n",
      "  Dropping 'Volume BTC_x_rolling_std_6h' (VIF: 23.99)\n",
      "  Dropping 'macd_signal_x_rolling_std_168h' (VIF: 23.50)\n",
      "  Dropping 'macd_signal' (VIF: 21.08)\n",
      "  Dropping 'lag_24h_price_return_x_std12_div_std72' (VIF: 20.84)\n",
      "  Dropping 'volume_ma_168h_x_bband_width_20h' (VIF: 20.50)\n",
      "  Dropping 'volume_div_ma_24h' (VIF: 20.38)\n",
      "  Dropping 'rolling_std_48h' (VIF: 20.14)\n",
      "  Dropping 'lag_12h_price_return_x_volume_div_ma_24h' (VIF: 19.72)\n",
      "  Dropping 'macd_hist_x_lag_24h_volume_return' (VIF: 18.52)\n",
      "  Dropping 'lag_168h_price_return' (VIF: 18.34)\n",
      "  Dropping 'macd_hist_x_rolling_std_48h' (VIF: 18.13)\n",
      "  Dropping 'lag_24h_price_return_x_rolling_std_6h' (VIF: 17.68)\n",
      "  Dropping 'Volume BTC' (VIF: 17.33)\n",
      "  Dropping 'lag_168h_price_return_x_volume_ma_12h' (VIF: 17.21)\n",
      "  Dropping 'lag_72h_price_return_x_Volume BTC' (VIF: 17.06)\n",
      "  Dropping 'volume_ma_12h_x_std12_div_std72' (VIF: 16.24)\n",
      "  Dropping 'lag_48h_price_return_x_std12_div_std72' (VIF: 15.89)\n",
      "  Dropping 'lag_72h_price_return_x_rolling_std_6h' (VIF: 15.72)\n",
      "  Dropping 'lag_12h_price_return_x_bband_width_20h' (VIF: 14.60)\n",
      "  Dropping 'bband_width_20h' (VIF: 14.19)\n",
      "  Dropping 'Volume BTC_x_bband_width_20h' (VIF: 13.46)\n",
      "  Dropping 'cci_20h_x_rolling_std_6h' (VIF: 13.26)\n",
      "  Dropping 'cci_20h_x_volume_ma_12h' (VIF: 13.15)\n",
      "  Dropping 'rolling_std_6h' (VIF: 12.42)\n",
      "  Dropping 'lag_24h_volume_return_x_rolling_kurt_24h' (VIF: 12.10)\n",
      "  Dropping 'macd_signal_x_volume_ma_168h' (VIF: 12.02)\n",
      "  Dropping 'volume_ma_168h_x_rolling_std_6h' (VIF: 11.86)\n",
      "  Dropping 'lag_24h_price_return_x_volume_div_ma_24h' (VIF: 11.34)\n",
      "  Dropping 'macd_signal_x_bband_width_20h' (VIF: 11.17)\n",
      "  Dropping 'cci_20h' (VIF: 10.87)\n",
      "  Dropping 'lag_72h_price_return' (VIF: 10.58)\n",
      "  Dropping 'volume_div_ma_24h_x_std12_div_std72' (VIF: 10.58)\n",
      "  Dropping 'lag_48h_price_return_x_rolling_kurt_24h' (VIF: 10.34)\n",
      "  Dropping 'lag_168h_price_return_x_rolling_std_48h' (VIF: 10.33)\n",
      "  Dropping 'lag_72h_price_return_x_lag_24h_volume_return' (VIF: 9.90)\n",
      "  Dropping 'macd_hist_x_volume_ma_168h' (VIF: 9.88)\n",
      "  Dropping 'cmf_20h_x_rolling_std_48h' (VIF: 9.77)\n",
      "  Dropping 'volume_div_ma_24h_x_rolling_std_48h' (VIF: 9.70)\n",
      "  Dropping 'lag_72h_price_return_x_volume_div_ma_24h' (VIF: 9.32)\n",
      "  Dropping 'macd_hist_x_bband_width_20h' (VIF: 9.00)\n",
      "  Dropping 'rolling_std_3h_sq_sqrt' (VIF: 8.99)\n",
      "  Dropping 'lag_24h_price_return_x_cmf_20h' (VIF: 8.46)\n",
      "  Dropping 'lag_24h_price_return_x_lag_24h_volume_return' (VIF: 8.45)\n",
      "  Dropping 'macd_hist_x_rolling_std_168h' (VIF: 8.41)\n",
      "  Dropping 'volume_ma_168h_x_rolling_std_168h' (VIF: 8.38)\n",
      "  Dropping 'volume_div_ma_24h_x_bband_width_20h' (VIF: 8.35)\n",
      "  Dropping 'lag_6h_volume_return_x_std12_div_std72' (VIF: 8.20)\n",
      "  Dropping 'Volume BTC_x_rolling_kurt_24h' (VIF: 8.03)\n",
      "  Dropping 'lag_48h_price_return_x_cmf_20h' (VIF: 7.94)\n",
      "  Dropping 'lag_72h_price_return_x_std12_div_std72' (VIF: 7.52)\n",
      "  Dropping 'volume_div_ma_24h_x_rolling_std_6h' (VIF: 7.32)\n",
      "  Dropping 'macd_hist_x_std12_div_std72' (VIF: 7.11)\n",
      "  Dropping 'macd_signal_x_Volume BTC' (VIF: 6.98)\n",
      "  Dropping 'lag_24h_price_return_x_rolling_kurt_24h' (VIF: 6.94)\n",
      "  Max VIF (6.63) is below threshold 6.9. Stopping.\n",
      "Removed 148 features based on VIF.\n",
      "  Features Dropped by VIF: ['Volume BTC', 'Volume BTC_log1p', 'Volume BTC_x_bband_width_20h', 'Volume BTC_x_rolling_kurt_24h', 'Volume BTC_x_rolling_std_48h', 'Volume BTC_x_rolling_std_6h', 'Volume USD_log1p', 'bband_width_20h', 'bband_width_20h_log1p', 'bband_width_20h_sqrt', 'cci_20h', 'cci_20h_x_bband_width_20h', 'cci_20h_x_lag_12h_volume_return', 'cci_20h_x_lag_6h_volume_return', 'cci_20h_x_rolling_std_6h', 'cci_20h_x_volume_ma_12h', 'cci_20h_x_volume_return_1h', 'cmf_20h_x_rolling_std_48h', 'lag_12h_price_return', 'lag_12h_price_return_x_Volume BTC', 'lag_12h_price_return_x_bband_width_20h', 'lag_12h_price_return_x_lag_12h_volume_return', 'lag_12h_price_return_x_lag_24h_volume_return', 'lag_12h_price_return_x_lag_3h_volume_return', 'lag_12h_price_return_x_lag_6h_volume_return', 'lag_12h_price_return_x_rolling_std_48h', 'lag_12h_price_return_x_rolling_std_6h', 'lag_12h_price_return_x_std12_div_std72', 'lag_12h_price_return_x_volume_div_ma_24h', 'lag_12h_price_return_x_volume_ma_12h', 'lag_12h_price_return_x_volume_return_1h', 'lag_12h_volume_return_x_bband_width_20h', 'lag_12h_volume_return_x_rolling_kurt_24h', 'lag_12h_volume_return_x_rolling_std_168h', 'lag_12h_volume_return_x_rolling_std_48h', 'lag_12h_volume_return_x_rolling_std_6h', 'lag_12h_volume_return_x_std12_div_std72', 'lag_168h_price_return', 'lag_168h_price_return_x_lag_12h_volume_return', 'lag_168h_price_return_x_lag_24h_volume_return', 'lag_168h_price_return_x_lag_3h_volume_return', 'lag_168h_price_return_x_lag_6h_volume_return', 'lag_168h_price_return_x_rolling_std_48h', 'lag_168h_price_return_x_volume_ma_12h', 'lag_168h_price_return_x_volume_return_1h', 'lag_24h_price_return', 'lag_24h_price_return_x_Volume BTC', 'lag_24h_price_return_x_bband_width_20h', 'lag_24h_price_return_x_cmf_20h', 'lag_24h_price_return_x_lag_24h_volume_return', 'lag_24h_price_return_x_lag_3h_volume_return', 'lag_24h_price_return_x_rolling_kurt_24h', 'lag_24h_price_return_x_rolling_std_48h', 'lag_24h_price_return_x_rolling_std_6h', 'lag_24h_price_return_x_std12_div_std72', 'lag_24h_price_return_x_volume_div_ma_24h', 'lag_24h_price_return_x_volume_ma_12h', 'lag_24h_price_return_x_volume_return_1h', 'lag_24h_volume_return', 'lag_24h_volume_return_x_bband_width_20h', 'lag_24h_volume_return_x_rolling_kurt_24h', 'lag_24h_volume_return_x_rolling_std_48h', 'lag_24h_volume_return_x_rolling_std_6h', 'lag_3h_volume_return', 'lag_3h_volume_return_x_bband_width_20h', 'lag_3h_volume_return_x_rolling_std_168h', 'lag_3h_volume_return_x_rolling_std_48h', 'lag_3h_volume_return_x_rolling_std_6h', 'lag_3h_volume_return_x_std12_div_std72', 'lag_48h_price_return', 'lag_48h_price_return_x_Volume BTC', 'lag_48h_price_return_x_bband_width_20h', 'lag_48h_price_return_x_cmf_20h', 'lag_48h_price_return_x_lag_12h_volume_return', 'lag_48h_price_return_x_lag_3h_volume_return', 'lag_48h_price_return_x_lag_6h_volume_return', 'lag_48h_price_return_x_rolling_kurt_24h', 'lag_48h_price_return_x_rolling_std_48h', 'lag_48h_price_return_x_rolling_std_6h', 'lag_48h_price_return_x_std12_div_std72', 'lag_48h_price_return_x_volume_ma_12h', 'lag_48h_price_return_x_volume_return_1h', 'lag_6h_volume_return', 'lag_6h_volume_return_x_bband_width_20h', 'lag_6h_volume_return_x_rolling_std_168h', 'lag_6h_volume_return_x_rolling_std_48h', 'lag_6h_volume_return_x_rolling_std_6h', 'lag_6h_volume_return_x_std12_div_std72', 'lag_72h_price_return', 'lag_72h_price_return_x_Volume BTC', 'lag_72h_price_return_x_bband_width_20h', 'lag_72h_price_return_x_lag_24h_volume_return', 'lag_72h_price_return_x_rolling_std_48h', 'lag_72h_price_return_x_rolling_std_6h', 'lag_72h_price_return_x_std12_div_std72', 'lag_72h_price_return_x_volume_div_ma_24h', 'lag_72h_price_return_x_volume_ma_12h', 'lag_72h_price_return_x_volume_return_1h', 'macd_hist', 'macd_hist_x_bband_width_20h', 'macd_hist_x_lag_12h_volume_return', 'macd_hist_x_lag_24h_volume_return', 'macd_hist_x_lag_3h_volume_return', 'macd_hist_x_lag_6h_volume_return', 'macd_hist_x_rolling_std_168h', 'macd_hist_x_rolling_std_48h', 'macd_hist_x_std12_div_std72', 'macd_hist_x_volume_ma_168h', 'macd_hist_x_volume_return_1h', 'macd_signal', 'macd_signal_x_Volume BTC', 'macd_signal_x_bband_width_20h', 'macd_signal_x_lag_12h_volume_return', 'macd_signal_x_lag_3h_volume_return', 'macd_signal_x_lag_6h_volume_return', 'macd_signal_x_rolling_std_168h', 'macd_signal_x_volume_ma_168h', 'macd_signal_x_volume_return_1h', 'rolling_std_168h_log1p', 'rolling_std_168h_sqrt', 'rolling_std_3h_sq_sqrt', 'rolling_std_48h', 'rolling_std_48h_log1p', 'rolling_std_48h_sqrt', 'rolling_std_6h', 'rolling_std_6h_log1p', 'rolling_std_6h_sqrt', 'volume_div_ma_24h', 'volume_div_ma_24h_x_bband_width_20h', 'volume_div_ma_24h_x_rolling_std_48h', 'volume_div_ma_24h_x_rolling_std_6h', 'volume_div_ma_24h_x_std12_div_std72', 'volume_ma_12h', 'volume_ma_12h_log1p', 'volume_ma_12h_x_rolling_std_168h', 'volume_ma_12h_x_rolling_std_48h', 'volume_ma_12h_x_std12_div_std72', 'volume_ma_168h', 'volume_ma_168h_log1p', 'volume_ma_168h_x_bband_width_20h', 'volume_ma_168h_x_rolling_std_168h', 'volume_ma_168h_x_rolling_std_6h', 'volume_return_1h_sq', 'volume_return_1h_x_bband_width_20h', 'volume_return_1h_x_rolling_std_168h', 'volume_return_1h_x_rolling_std_48h', 'volume_return_1h_x_rolling_std_6h', 'volume_return_1h_x_std12_div_std72']\n",
      "Features remaining after VIF check: 123\n",
      "--- VIF calculation finished. ---\n",
      "\n",
      "--- 9. Final Selection Summary (Post-Advanced Engineering) ---\n",
      "Features after initial VIF:              58\n",
      "Features after advanced eng+transform: 271\n",
      "Features after final VIF (6.9):      123\n",
      "\n",
      "Final list of selected feature names (after second VIF pass):\n",
      "  1. Volume BTC_x_rolling_std_168h\n",
      "  2. Volume BTC_x_std12_div_std72\n",
      "  3. Volume USD\n",
      "  4. cci_20h_sq\n",
      "  5. cci_20h_x_Volume BTC\n",
      "  6. cci_20h_x_cmf_20h\n",
      "  7. cci_20h_x_lag_24h_volume_return\n",
      "  8. cci_20h_x_lag_3h_volume_return\n",
      "  9. cci_20h_x_rolling_kurt_24h\n",
      "  10. cci_20h_x_rolling_std_168h\n",
      "  11. cci_20h_x_rolling_std_48h\n",
      "  12. cci_20h_x_std12_div_std72\n",
      "  13. cci_20h_x_volume_div_ma_24h\n",
      "  14. cci_20h_x_volume_ma_168h\n",
      "  15. close_pos_in_range\n",
      "  16. cmf_20h\n",
      "  17. cmf_20h_x_bband_width_20h\n",
      "  18. cmf_20h_x_rolling_kurt_24h\n",
      "  19. cmf_20h_x_rolling_std_168h\n",
      "  20. cmf_20h_x_rolling_std_6h\n",
      "  21. cmf_20h_x_std12_div_std72\n",
      "  22. day_0\n",
      "  23. day_1\n",
      "  24. day_2\n",
      "  25. day_4\n",
      "  26. day_5\n",
      "  27. day_6\n",
      "  28. hour_0\n",
      "  29. hour_1\n",
      "  30. hour_10\n",
      "  31. hour_11\n",
      "  32. hour_12\n",
      "  33. hour_13\n",
      "  34. hour_14\n",
      "  35. hour_15\n",
      "  36. hour_16\n",
      "  37. hour_17\n",
      "  38. hour_18\n",
      "  39. hour_19\n",
      "  40. hour_2\n",
      "  41. hour_20\n",
      "  42. hour_21\n",
      "  43. hour_22\n",
      "  44. hour_23\n",
      "  45. hour_3\n",
      "  46. hour_4\n",
      "  47. hour_5\n",
      "  48. hour_6\n",
      "  49. hour_8\n",
      "  50. hour_9\n",
      "  51. lag_12h_price_return_sq\n",
      "  52. lag_12h_price_return_x_cmf_20h\n",
      "  53. lag_12h_price_return_x_rolling_kurt_24h\n",
      "  54. lag_12h_price_return_x_rolling_std_168h\n",
      "  55. lag_12h_price_return_x_volume_ma_168h\n",
      "  56. lag_12h_volume_return\n",
      "  57. lag_168h_price_return_sq\n",
      "  58. lag_168h_price_return_x_Volume BTC\n",
      "  59. lag_168h_price_return_x_bband_width_20h\n",
      "  60. lag_168h_price_return_x_cmf_20h\n",
      "  61. lag_168h_price_return_x_rolling_kurt_24h\n",
      "  62. lag_168h_price_return_x_rolling_std_168h\n",
      "  63. lag_168h_price_return_x_rolling_std_6h\n",
      "  64. lag_168h_price_return_x_std12_div_std72\n",
      "  65. lag_168h_price_return_x_volume_div_ma_24h\n",
      "  66. lag_168h_price_return_x_volume_ma_168h\n",
      "  67. lag_24h_price_return_sq\n",
      "  68. lag_24h_price_return_x_lag_12h_volume_return\n",
      "  69. lag_24h_price_return_x_lag_6h_volume_return\n",
      "  70. lag_24h_price_return_x_rolling_std_168h\n",
      "  71. lag_24h_price_return_x_volume_ma_168h\n",
      "  72. lag_24h_volume_return_x_rolling_std_168h\n",
      "  73. lag_24h_volume_return_x_std12_div_std72\n",
      "  74. lag_3h_volume_return_x_rolling_kurt_24h\n",
      "  75. lag_48h_price_return_sq\n",
      "  76. lag_48h_price_return_x_lag_24h_volume_return\n",
      "  77. lag_48h_price_return_x_rolling_std_168h\n",
      "  78. lag_48h_price_return_x_volume_div_ma_24h\n",
      "  79. lag_48h_price_return_x_volume_ma_168h\n",
      "  80. lag_6h_volume_return_x_rolling_kurt_24h\n",
      "  81. lag_72h_price_return_sq\n",
      "  82. lag_72h_price_return_x_cmf_20h\n",
      "  83. lag_72h_price_return_x_lag_12h_volume_return\n",
      "  84. lag_72h_price_return_x_lag_3h_volume_return\n",
      "  85. lag_72h_price_return_x_lag_6h_volume_return\n",
      "  86. lag_72h_price_return_x_rolling_kurt_24h\n",
      "  87. lag_72h_price_return_x_rolling_std_168h\n",
      "  88. lag_72h_price_return_x_volume_ma_168h\n",
      "  89. macd_hist_sq\n",
      "  90. macd_hist_x_Volume BTC\n",
      "  91. macd_hist_x_cmf_20h\n",
      "  92. macd_hist_x_rolling_kurt_24h\n",
      "  93. macd_hist_x_rolling_std_6h\n",
      "  94. macd_hist_x_volume_div_ma_24h\n",
      "  95. macd_hist_x_volume_ma_12h\n",
      "  96. macd_signal_sq\n",
      "  97. macd_signal_x_cmf_20h\n",
      "  98. macd_signal_x_lag_24h_volume_return\n",
      "  99. macd_signal_x_rolling_kurt_24h\n",
      "  100. macd_signal_x_rolling_std_48h\n",
      "  101. macd_signal_x_rolling_std_6h\n",
      "  102. macd_signal_x_std12_div_std72\n",
      "  103. macd_signal_x_volume_div_ma_24h\n",
      "  104. macd_signal_x_volume_ma_12h\n",
      "  105. rolling_kurt_24h\n",
      "  106. rolling_skew_24h\n",
      "  107. rolling_std_168h\n",
      "  108. rolling_std_3h_sq\n",
      "  109. rolling_std_6h_div_rolling_std_48h\n",
      "  110. std12_div_std72\n",
      "  111. volume_btc_x_range\n",
      "  112. volume_btc_x_range_log1p\n",
      "  113. volume_div_ma_24h_sq\n",
      "  114. volume_div_ma_24h_x_rolling_kurt_24h\n",
      "  115. volume_div_ma_24h_x_rolling_std_168h\n",
      "  116. volume_ma_12h_x_bband_width_20h\n",
      "  117. volume_ma_12h_x_rolling_kurt_24h\n",
      "  118. volume_ma_12h_x_rolling_std_6h\n",
      "  119. volume_ma_168h_x_rolling_kurt_24h\n",
      "  120. volume_ma_168h_x_rolling_std_48h\n",
      "  121. volume_ma_168h_x_std12_div_std72\n",
      "  122. volume_return_1h\n",
      "  123. volume_return_1h_x_rolling_kurt_24h\n",
      "\n",
      "Total final selected features: 123\n",
      "\n",
      "Advanced feature engineering and selection script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "\n",
    "# Assume the following variables are available from the previous steps:\n",
    "# - df_full_features: DataFrame containing all original columns + engineered features\n",
    "# - features_after_vif: List of the 58 feature names that survived the first VIF pass\n",
    "# - calculate_vif: The helper function for VIF calculation (defined previously)\n",
    "\n",
    "print(\"\\n--- 7. Advanced Feature Engineering (Post-Initial VIF) ---\")\n",
    "\n",
    "# Make sure features_after_vif is not empty\n",
    "if not features_after_vif:\n",
    "    print(\"Skipping advanced feature engineering: No features survived initial VIF.\")\n",
    "    final_selected_features = []\n",
    "else:\n",
    "    print(f\"Starting with {len(features_after_vif)} features selected by initial VIF.\")\n",
    "\n",
    "    # Create a DataFrame with only the selected features for engineering\n",
    "    df_eng = df_full_features[features_after_vif].copy()\n",
    "    engineered_feature_names = list(features_after_vif) # Keep track\n",
    "\n",
    "    # --- A. Univariate Transformations ---\n",
    "    print(\"\\n  --- A. Applying Univariate Transformations ---\")\n",
    "    # Define candidates based on names/types (adjust based on your actual feature list)\n",
    "    # Ensure candidates actually exist in df_eng.columns\n",
    "    cols_for_log = [c for c in ['Volume BTC', 'Volume USD', 'volume_ma_12h', 'volume_ma_168h', 'rolling_std_6h', 'rolling_std_48h', 'rolling_std_168h', 'bband_width_20h', 'volume_btc_x_range'] if c in df_eng.columns]\n",
    "    cols_for_sqrt = [c for c in ['rolling_std_6h', 'rolling_std_48h', 'rolling_std_168h', 'rolling_std_3h_sq', 'bband_width_20h'] if c in df_eng.columns] # Non-negative candidates\n",
    "    cols_for_sq = [c for c in ['lag_12h_price_return', 'lag_24h_price_return', 'lag_48h_price_return', 'lag_72h_price_return', 'lag_168h_price_return', 'macd_hist', 'macd_signal', 'cci_20h', 'volume_return_1h', 'volume_div_ma_24h'] if c in df_eng.columns]\n",
    "\n",
    "    print(f\"  Applying log1p to {len(cols_for_log)} features...\")\n",
    "    for col in cols_for_log:\n",
    "        new_col_name = f\"{col}_log1p\"\n",
    "        # Use log1p for stability with zeros; add small epsilon if negatives are possible and unwanted\n",
    "        df_eng[new_col_name] = np.log1p(df_eng[col].fillna(0).clip(lower=0)) # fillna(0) before log, ensure non-negative\n",
    "        engineered_feature_names.append(new_col_name)\n",
    "\n",
    "    print(f\"  Applying sqrt to {len(cols_for_sqrt)} features...\")\n",
    "    for col in cols_for_sqrt:\n",
    "        new_col_name = f\"{col}_sqrt\"\n",
    "        # Use np.abs for safety, though these should be non-negative\n",
    "        with np.errstate(invalid='ignore'): # Ignore warnings for sqrt(negative) if abs wasn't used\n",
    "             df_eng[new_col_name] = np.sqrt(np.abs(df_eng[col].fillna(0)))\n",
    "        engineered_feature_names.append(new_col_name)\n",
    "\n",
    "    print(f\"  Applying square to {len(cols_for_sq)} features...\")\n",
    "    for col in cols_for_sq:\n",
    "        new_col_name = f\"{col}_sq\"\n",
    "        df_eng[new_col_name] = df_eng[col].fillna(0) ** 2\n",
    "        engineered_feature_names.append(new_col_name)\n",
    "\n",
    "    # --- B. Bivariate Interactions (Multiplication) ---\n",
    "    print(\"\\n  --- B. Creating Interaction Terms (Multiplication) ---\")\n",
    "    # Define categories based on feature names (adjust to your list!)\n",
    "    # Ensure these lists only contain features PRESENT in df_eng.columns\n",
    "    momentum_cols = [c for c in ['lag_12h_price_return', 'lag_24h_price_return', 'lag_48h_price_return', 'lag_72h_price_return', 'lag_168h_price_return', 'macd_hist', 'macd_signal', 'cci_20h'] if c in df_eng.columns]\n",
    "    volume_cols = [c for c in ['Volume BTC', 'lag_12h_volume_return', 'lag_24h_volume_return', 'lag_3h_volume_return', 'lag_6h_volume_return', 'volume_ma_12h', 'volume_ma_168h', 'volume_div_ma_24h', 'volume_return_1h', 'cmf_20h'] if c in df_eng.columns]\n",
    "    volatility_cols = [c for c in ['rolling_std_6h', 'rolling_std_48h', 'rolling_std_168h', 'bband_width_20h', 'std12_div_std72', 'rolling_kurt_24h'] if c in df_eng.columns] # Include Kurtosis as proxy?\n",
    "\n",
    "    interaction_pairs = []\n",
    "    # Momentum x Volume\n",
    "    for m_col in momentum_cols:\n",
    "        for v_col in volume_cols:\n",
    "            # Avoid self-interaction if somehow a col is in both lists\n",
    "            if m_col != v_col: interaction_pairs.append((m_col, v_col))\n",
    "    # Momentum x Volatility\n",
    "    for m_col in momentum_cols:\n",
    "        for vo_col in volatility_cols:\n",
    "            if m_col != vo_col: interaction_pairs.append((m_col, vo_col))\n",
    "    # Volume x Volatility\n",
    "    for v_col in volume_cols:\n",
    "        for vo_col in volatility_cols:\n",
    "             if v_col != vo_col: interaction_pairs.append((v_col, vo_col))\n",
    "\n",
    "    # Remove duplicate pairs if any category overlaps\n",
    "    interaction_pairs = list(set(interaction_pairs))\n",
    "    print(f\"  Creating {len(interaction_pairs)} interaction features...\")\n",
    "\n",
    "    interaction_count = 0\n",
    "    for col1, col2 in interaction_pairs:\n",
    "        # Check if both columns still exist (might have been removed if categories overlapped)\n",
    "        if col1 in df_eng.columns and col2 in df_eng.columns:\n",
    "            new_col_name = f\"{col1}_x_{col2}\"\n",
    "            # Fill NaNs with 0 before multiplication? Or let NaNs propagate? Propagate is often better.\n",
    "            df_eng[new_col_name] = df_eng[col1] * df_eng[col2]\n",
    "            engineered_feature_names.append(new_col_name)\n",
    "            interaction_count += 1\n",
    "        # else: # Debugging if needed\n",
    "        #     print(f\"Skipping interaction: {col1} or {col2} not found.\")\n",
    "\n",
    "    print(f\"  Successfully created {interaction_count} interaction features.\")\n",
    "\n",
    "    # --- C. Bivariate Interactions (Division / Ratios) ---\n",
    "    # Be very selective. Example: std_short / std_long (if not already present)\n",
    "    print(\"\\n  --- C. Creating Interaction Terms (Division - Selective) ---\")\n",
    "    ratio_pairs = []\n",
    "    # Example: if 'rolling_std_6h' and 'rolling_std_48h' survived\n",
    "    if 'rolling_std_6h' in df_eng.columns and 'rolling_std_48h' in df_eng.columns:\n",
    "        ratio_pairs.append(('rolling_std_6h', 'rolling_std_48h'))\n",
    "    # Add other theoretically sound pairs IF NEEDED\n",
    "\n",
    "    print(f\"  Creating {len(ratio_pairs)} ratio features...\")\n",
    "    epsilon = 1e-9 # Small number to avoid division by zero\n",
    "    for num_col, den_col in ratio_pairs:\n",
    "         if num_col in df_eng.columns and den_col in df_eng.columns:\n",
    "            new_col_name = f\"{num_col}_div_{den_col}\"\n",
    "            # Handle division by zero robustly\n",
    "            denominator = df_eng[den_col].fillna(0) # Fill NaNs in denominator? Risky if 0 is meaningful.\n",
    "            df_eng[new_col_name] = df_eng[num_col].fillna(0) / (denominator + np.sign(denominator)*epsilon + epsilon) # Add epsilon based on sign\n",
    "            # Alternatively, use np.where\n",
    "            # df_eng[new_col_name] = np.where(\n",
    "            #     np.abs(denominator) > epsilon,\n",
    "            #     df_eng[num_col].fillna(0) / denominator,\n",
    "            #     0 # Or np.nan, or median, etc.\n",
    "            # )\n",
    "            engineered_feature_names.append(new_col_name)\n",
    "\n",
    "    # --- D. Clean Up Engineered Features ---\n",
    "    print(\"\\n  --- D. Cleaning Engineered Features ---\")\n",
    "    # Remove duplicates from the list (if any transformation/interaction created same name)\n",
    "    engineered_feature_names = sorted(list(set(engineered_feature_names)))\n",
    "    # Ensure all listed features are actually columns in df_eng\n",
    "    engineered_feature_names = [f for f in engineered_feature_names if f in df_eng.columns]\n",
    "\n",
    "    # Select only the columns intended for the final VIF check\n",
    "    df_eng_final = df_eng[engineered_feature_names].copy()\n",
    "\n",
    "    # Replace any new infinities created (e.g., by division) with NaN\n",
    "    inf_count_before = np.isinf(df_eng_final.values).sum()\n",
    "    df_eng_final.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    inf_count_after = np.isinf(df_eng_final.values).sum()\n",
    "    if inf_count_before > inf_count_after:\n",
    "        print(f\"  Replaced {inf_count_before - inf_count_after} new infinite values with NaN.\")\n",
    "\n",
    "    print(f\"Total features after advanced engineering: {len(df_eng_final.columns)}\")\n",
    "\n",
    "    # --- E. Run VIF Again on the Expanded Set ---\n",
    "    print(\"\\n--- 8. Running VIF on Expanded Feature Set ---\")\n",
    "    # Use the same VIF threshold as before, or potentially a slightly higher one if needed\n",
    "    final_selected_features = calculate_vif(\n",
    "        df_eng_final,\n",
    "        vif_threshold=VIF_THRESHOLD, # Use the globally defined threshold\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # --- F. Final Output ---\n",
    "    print(f\"\\n--- 9. Final Selection Summary (Post-Advanced Engineering) ---\")\n",
    "    print(f\"Features after initial VIF:              {len(features_after_vif)}\")\n",
    "    print(f\"Features after advanced eng+transform: {len(df_eng_final.columns)}\")\n",
    "    print(f\"Features after final VIF ({VIF_THRESHOLD}):      {len(final_selected_features)}\")\n",
    "    print(\"\\nFinal list of selected feature names (after second VIF pass):\")\n",
    "    if final_selected_features:\n",
    "        for i, feature in enumerate(sorted(final_selected_features)): # Sort alphabetically\n",
    "            print(f\"  {i+1}. {feature}\")\n",
    "    else:\n",
    "        print(\"  No features remained after the final VIF filtering.\")\n",
    "\n",
    "    print(f\"\\nTotal final selected features: {len(final_selected_features)}\")\n",
    "\n",
    "# Add a final message outside the else block\n",
    "print(\"\\nAdvanced feature engineering and selection script finished.\")\n",
    "\n",
    "# The variable 'final_selected_features' now holds the names of the features\n",
    "# that survived both rounds of VIF filtering.\n",
    "# You would use this list in your subsequent modeling steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 7. Advanced Feature Engineering (Post-Initial VIF) ---\n",
    "Starting with 58 features selected by initial VIF.\n",
    "\n",
    "  --- A. Applying Univariate Transformations ---\n",
    "  Applying log1p to 9 features...\n",
    "  Applying sqrt to 5 features...\n",
    "  Applying square to 10 features...\n",
    "\n",
    "  --- B. Creating Interaction Terms (Multiplication) ---\n",
    "  Creating 188 interaction features...\n",
    "  Successfully created 188 interaction features.\n",
    "\n",
    "  --- C. Creating Interaction Terms (Division - Selective) ---\n",
    "  Creating 1 ratio features...\n",
    "\n",
    "  --- D. Cleaning Engineered Features ---\n",
    "Total features after advanced engineering: 271\n",
    "\n",
    "--- 8. Running VIF on Expanded Feature Set ---\n",
    "\n",
    "--- Feature Selection: Calculating VIF (Threshold: 6.9) ---\n",
    "Features before VIF check: 271\n",
    "  Warning: Found 8602 NaNs. Imputing with column medians for VIF calculation ONLY.\n",
    "  Dropping 'volume_return_1h_x_rolling_std_48h' (VIF: 404620.59)\n",
    "  Dropping 'macd_signal_x_volume_return_1h' (VIF: 211199.78)\n",
    "  Dropping 'lag_48h_price_return_x_volume_return_1h' (VIF: 102324.20)\n",
    "  Dropping 'volume_return_1h_sq' (VIF: 78528.17)\n",
    "  Dropping 'volume_return_1h_x_rolling_std_168h' (VIF: 59399.18)\n",
    "  Dropping 'lag_72h_price_return_x_volume_return_1h' (VIF: 41367.88)\n",
    "  Dropping 'volume_return_1h_x_bband_width_20h' (VIF: 32665.66)\n",
    "  Dropping 'lag_168h_price_return_x_volume_return_1h' (VIF: 21942.96)\n",
    "  Dropping 'lag_6h_volume_return_x_rolling_std_48h' (VIF: 16193.96)\n",
    "  Dropping 'lag_12h_volume_return_x_rolling_std_48h' (VIF: 13149.26)\n",
    "  Dropping 'lag_3h_volume_return_x_rolling_std_48h' (VIF: 11874.49)\n",
    "  Dropping 'volume_return_1h_x_rolling_std_6h' (VIF: 9517.35)\n",
    "  Dropping 'volume_return_1h_x_std12_div_std72' (VIF: 8361.00)\n",
    "  Dropping 'lag_3h_volume_return_x_rolling_std_168h' (VIF: 4202.18)\n",
    "  Dropping 'lag_6h_volume_return_x_rolling_std_168h' (VIF: 4140.54)\n",
    "  Dropping 'lag_12h_volume_return_x_rolling_std_168h' (VIF: 3688.98)\n",
    "  Dropping 'macd_signal_x_lag_3h_volume_return' (VIF: 3442.17)\n",
    "  Dropping 'lag_12h_volume_return_x_bband_width_20h' (VIF: 3215.48)\n",
    "  Dropping 'rolling_std_168h_log1p' (VIF: 3156.73)\n",
    "  Dropping 'bband_width_20h_sqrt' (VIF: 15963.25)\n",
    "  Dropping 'lag_48h_price_return_x_lag_3h_volume_return' (VIF: 2773.80)\n",
    "  Dropping 'macd_hist_x_lag_12h_volume_return' (VIF: 2693.97)\n",
    "  Dropping 'macd_hist_x_lag_6h_volume_return' (VIF: 2594.53)\n",
    "  Dropping 'lag_3h_volume_return' (VIF: 2541.81)\n",
    "  Dropping 'lag_12h_price_return_x_volume_return_1h' (VIF: 2127.71)\n",
    "  Dropping 'lag_6h_volume_return_x_bband_width_20h' (VIF: 1844.85)\n",
    "  Dropping 'macd_signal_x_lag_6h_volume_return' (VIF: 1700.96)\n",
    "  Dropping 'rolling_std_48h_log1p' (VIF: 1497.23)\n",
    "  Dropping 'lag_168h_price_return_x_lag_6h_volume_return' (VIF: 1459.85)\n",
    "  Dropping 'lag_168h_price_return_x_lag_12h_volume_return' (VIF: 1324.18)\n",
    "  Dropping 'macd_hist_x_volume_return_1h' (VIF: 1293.36)\n",
    "  Dropping 'lag_3h_volume_return_x_bband_width_20h' (VIF: 954.81)\n",
    "  Dropping 'rolling_std_6h_log1p' (VIF: 794.20)\n",
    "  Dropping 'lag_168h_price_return_x_lag_3h_volume_return' (VIF: 755.22)\n",
    "  Dropping 'Volume BTC_log1p' (VIF: 752.67)\n",
    "  Dropping 'lag_12h_volume_return_x_rolling_std_6h' (VIF: 717.26)\n",
    "  Dropping 'lag_6h_volume_return_x_rolling_std_6h' (VIF: 696.36)\n",
    "  Dropping 'lag_12h_volume_return_x_std12_div_std72' (VIF: 508.86)\n",
    "  Dropping 'macd_hist_x_lag_3h_volume_return' (VIF: 432.61)\n",
    "  Dropping 'lag_12h_price_return_x_lag_12h_volume_return' (VIF: 406.68)\n",
    "  Dropping 'rolling_std_48h_sqrt' (VIF: 379.80)\n",
    "  Dropping 'lag_6h_volume_return' (VIF: 364.92)\n",
    "  Dropping 'volume_ma_12h_log1p' (VIF: 361.34)\n",
    "  Dropping 'lag_3h_volume_return_x_std12_div_std72' (VIF: 308.28)\n",
    "  Dropping 'lag_24h_volume_return' (VIF: 298.66)\n",
    "  Dropping 'lag_24h_volume_return_x_rolling_std_48h' (VIF: 264.86)\n",
    "  Dropping 'macd_signal_x_lag_12h_volume_return' (VIF: 256.97)\n",
    "  Dropping 'lag_48h_price_return_x_lag_6h_volume_return' (VIF: 233.08)\n",
    "  Dropping 'rolling_std_168h_sqrt' (VIF: 202.52)\n",
    "  Dropping 'cci_20h_x_volume_return_1h' (VIF: 156.38)\n",
    "  Dropping 'lag_12h_price_return_x_lag_3h_volume_return' (VIF: 148.14)\n",
    "  Dropping 'rolling_std_6h_sqrt' (VIF: 139.99)\n",
    "  Dropping 'lag_48h_price_return_x_lag_12h_volume_return' (VIF: 112.16)\n",
    "  Dropping 'bband_width_20h_log1p' (VIF: 106.75)\n",
    "  Dropping 'volume_ma_168h_log1p' (VIF: 99.71)\n",
    "  Dropping 'lag_24h_price_return_x_volume_ma_12h' (VIF: 97.83)\n",
    "  Dropping 'lag_24h_volume_return_x_bband_width_20h' (VIF: 94.86)\n",
    "  Dropping 'lag_48h_price_return_x_volume_ma_12h' (VIF: 88.00)\n",
    "  Dropping 'cci_20h_x_lag_12h_volume_return' (VIF: 80.29)\n",
    "  Dropping 'volume_ma_12h_x_rolling_std_48h' (VIF: 78.87)\n",
    "  Dropping 'lag_12h_price_return_x_lag_24h_volume_return' (VIF: 71.70)\n",
    "  Dropping 'lag_24h_price_return_x_lag_3h_volume_return' (VIF: 70.60)\n",
    "  Dropping 'lag_12h_price_return_x_volume_ma_12h' (VIF: 63.35)\n",
    "  Dropping 'lag_48h_price_return_x_bband_width_20h' (VIF: 62.72)\n",
    "  Dropping 'lag_24h_volume_return_x_rolling_std_6h' (VIF: 59.18)\n",
    "  Dropping 'lag_24h_price_return_x_volume_return_1h' (VIF: 56.08)\n",
    "  Dropping 'lag_24h_price_return_x_Volume BTC' (VIF: 50.76)\n",
    "  Dropping 'lag_12h_price_return' (VIF: 49.05)\n",
    "  Dropping 'lag_48h_price_return_x_rolling_std_48h' (VIF: 46.67)\n",
    "  Dropping 'volume_ma_168h' (VIF: 46.17)\n",
    "  Dropping 'lag_24h_price_return_x_rolling_std_48h' (VIF: 44.88)\n",
    "  Dropping 'Volume USD_log1p' (VIF: 43.65)\n",
    "  Dropping 'lag_72h_price_return_x_volume_ma_12h' (VIF: 43.36)\n",
    "  Dropping 'lag_12h_price_return_x_lag_6h_volume_return' (VIF: 42.43)\n",
    "  Dropping 'lag_48h_price_return_x_Volume BTC' (VIF: 39.41)\n",
    "  Dropping 'lag_24h_price_return' (VIF: 35.87)\n",
    "  Dropping 'volume_ma_12h_x_rolling_std_168h' (VIF: 34.75)\n",
    "  Dropping 'lag_24h_price_return_x_bband_width_20h' (VIF: 34.66)\n",
    "  Dropping 'lag_12h_price_return_x_rolling_std_6h' (VIF: 34.53)\n",
    "  Dropping 'lag_72h_price_return_x_rolling_std_48h' (VIF: 32.35)\n",
    "  Dropping 'lag_48h_price_return' (VIF: 31.48)\n",
    "  Dropping 'lag_168h_price_return_x_lag_24h_volume_return' (VIF: 31.24)\n",
    "  Dropping 'Volume BTC_x_rolling_std_48h' (VIF: 30.57)\n",
    "  Dropping 'lag_12h_price_return_x_rolling_std_48h' (VIF: 30.15)\n",
    "  Dropping 'lag_12h_volume_return_x_rolling_kurt_24h' (VIF: 29.90)\n",
    "  Dropping 'cci_20h_x_bband_width_20h' (VIF: 28.45)\n",
    "  Dropping 'lag_12h_price_return_x_std12_div_std72' (VIF: 27.83)\n",
    "  Dropping 'lag_48h_price_return_x_rolling_std_6h' (VIF: 27.40)\n",
    "  Dropping 'lag_3h_volume_return_x_rolling_std_6h' (VIF: 27.38)\n",
    "  Dropping 'lag_72h_price_return_x_bband_width_20h' (VIF: 25.71)\n",
    "  Dropping 'macd_hist' (VIF: 25.41)\n",
    "  Dropping 'lag_12h_price_return_x_Volume BTC' (VIF: 25.36)\n",
    "  Dropping 'cci_20h_x_lag_6h_volume_return' (VIF: 24.64)\n",
    "  Dropping 'volume_ma_12h' (VIF: 24.54)\n",
    "  Dropping 'Volume BTC_x_rolling_std_6h' (VIF: 23.99)\n",
    "  Dropping 'macd_signal_x_rolling_std_168h' (VIF: 23.50)\n",
    "  Dropping 'macd_signal' (VIF: 21.08)\n",
    "  Dropping 'lag_24h_price_return_x_std12_div_std72' (VIF: 20.84)\n",
    "  Dropping 'volume_ma_168h_x_bband_width_20h' (VIF: 20.50)\n",
    "  Dropping 'volume_div_ma_24h' (VIF: 20.38)\n",
    "  Dropping 'rolling_std_48h' (VIF: 20.14)\n",
    "  Dropping 'lag_12h_price_return_x_volume_div_ma_24h' (VIF: 19.72)\n",
    "  Dropping 'macd_hist_x_lag_24h_volume_return' (VIF: 18.52)\n",
    "  Dropping 'lag_168h_price_return' (VIF: 18.34)\n",
    "  Dropping 'macd_hist_x_rolling_std_48h' (VIF: 18.13)\n",
    "  Dropping 'lag_24h_price_return_x_rolling_std_6h' (VIF: 17.68)\n",
    "  Dropping 'Volume BTC' (VIF: 17.33)\n",
    "  Dropping 'lag_168h_price_return_x_volume_ma_12h' (VIF: 17.21)\n",
    "  Dropping 'lag_72h_price_return_x_Volume BTC' (VIF: 17.06)\n",
    "  Dropping 'volume_ma_12h_x_std12_div_std72' (VIF: 16.24)\n",
    "  Dropping 'lag_48h_price_return_x_std12_div_std72' (VIF: 15.89)\n",
    "  Dropping 'lag_72h_price_return_x_rolling_std_6h' (VIF: 15.72)\n",
    "  Dropping 'lag_12h_price_return_x_bband_width_20h' (VIF: 14.60)\n",
    "  Dropping 'bband_width_20h' (VIF: 14.19)\n",
    "  Dropping 'Volume BTC_x_bband_width_20h' (VIF: 13.46)\n",
    "  Dropping 'cci_20h_x_rolling_std_6h' (VIF: 13.26)\n",
    "  Dropping 'cci_20h_x_volume_ma_12h' (VIF: 13.15)\n",
    "  Dropping 'rolling_std_6h' (VIF: 12.42)\n",
    "  Dropping 'lag_24h_volume_return_x_rolling_kurt_24h' (VIF: 12.10)\n",
    "  Dropping 'macd_signal_x_volume_ma_168h' (VIF: 12.02)\n",
    "  Dropping 'volume_ma_168h_x_rolling_std_6h' (VIF: 11.86)\n",
    "  Dropping 'lag_24h_price_return_x_volume_div_ma_24h' (VIF: 11.34)\n",
    "  Dropping 'macd_signal_x_bband_width_20h' (VIF: 11.17)\n",
    "  Dropping 'cci_20h' (VIF: 10.87)\n",
    "  Dropping 'lag_72h_price_return' (VIF: 10.58)\n",
    "  Dropping 'volume_div_ma_24h_x_std12_div_std72' (VIF: 10.58)\n",
    "  Dropping 'lag_48h_price_return_x_rolling_kurt_24h' (VIF: 10.34)\n",
    "  Dropping 'lag_168h_price_return_x_rolling_std_48h' (VIF: 10.33)\n",
    "  Dropping 'lag_72h_price_return_x_lag_24h_volume_return' (VIF: 9.90)\n",
    "  Dropping 'macd_hist_x_volume_ma_168h' (VIF: 9.88)\n",
    "  Dropping 'cmf_20h_x_rolling_std_48h' (VIF: 9.77)\n",
    "  Dropping 'volume_div_ma_24h_x_rolling_std_48h' (VIF: 9.70)\n",
    "  Dropping 'lag_72h_price_return_x_volume_div_ma_24h' (VIF: 9.32)\n",
    "  Dropping 'macd_hist_x_bband_width_20h' (VIF: 9.00)\n",
    "  Dropping 'rolling_std_3h_sq_sqrt' (VIF: 8.99)\n",
    "  Dropping 'lag_24h_price_return_x_cmf_20h' (VIF: 8.46)\n",
    "  Dropping 'lag_24h_price_return_x_lag_24h_volume_return' (VIF: 8.45)\n",
    "  Dropping 'macd_hist_x_rolling_std_168h' (VIF: 8.41)\n",
    "  Dropping 'volume_ma_168h_x_rolling_std_168h' (VIF: 8.38)\n",
    "  Dropping 'volume_div_ma_24h_x_bband_width_20h' (VIF: 8.35)\n",
    "  Dropping 'lag_6h_volume_return_x_std12_div_std72' (VIF: 8.20)\n",
    "  Dropping 'Volume BTC_x_rolling_kurt_24h' (VIF: 8.03)\n",
    "  Dropping 'lag_48h_price_return_x_cmf_20h' (VIF: 7.94)\n",
    "  Dropping 'lag_72h_price_return_x_std12_div_std72' (VIF: 7.52)\n",
    "  Dropping 'volume_div_ma_24h_x_rolling_std_6h' (VIF: 7.32)\n",
    "  Dropping 'macd_hist_x_std12_div_std72' (VIF: 7.11)\n",
    "  Dropping 'macd_signal_x_Volume BTC' (VIF: 6.98)\n",
    "  Dropping 'lag_24h_price_return_x_rolling_kurt_24h' (VIF: 6.94)\n",
    "  Max VIF (6.63) is below threshold 6.9. Stopping.\n",
    "Removed 148 features based on VIF.\n",
    "  Features Dropped by VIF: ['Volume BTC', 'Volume BTC_log1p', 'Volume BTC_x_bband_width_20h', 'Volume BTC_x_rolling_kurt_24h', 'Volume BTC_x_rolling_std_48h', 'Volume BTC_x_rolling_std_6h', 'Volume USD_log1p', 'bband_width_20h', 'bband_width_20h_log1p', 'bband_width_20h_sqrt', 'cci_20h', 'cci_20h_x_bband_width_20h', 'cci_20h_x_lag_12h_volume_return', 'cci_20h_x_lag_6h_volume_return', 'cci_20h_x_rolling_std_6h', 'cci_20h_x_volume_ma_12h', 'cci_20h_x_volume_return_1h', 'cmf_20h_x_rolling_std_48h', 'lag_12h_price_return', 'lag_12h_price_return_x_Volume BTC', 'lag_12h_price_return_x_bband_width_20h', 'lag_12h_price_return_x_lag_12h_volume_return', 'lag_12h_price_return_x_lag_24h_volume_return', 'lag_12h_price_return_x_lag_3h_volume_return', 'lag_12h_price_return_x_lag_6h_volume_return', 'lag_12h_price_return_x_rolling_std_48h', 'lag_12h_price_return_x_rolling_std_6h', 'lag_12h_price_return_x_std12_div_std72', 'lag_12h_price_return_x_volume_div_ma_24h', 'lag_12h_price_return_x_volume_ma_12h', 'lag_12h_price_return_x_volume_return_1h', 'lag_12h_volume_return_x_bband_width_20h', 'lag_12h_volume_return_x_rolling_kurt_24h', 'lag_12h_volume_return_x_rolling_std_168h', 'lag_12h_volume_return_x_rolling_std_48h', 'lag_12h_volume_return_x_rolling_std_6h', 'lag_12h_volume_return_x_std12_div_std72', 'lag_168h_price_return', 'lag_168h_price_return_x_lag_12h_volume_return', 'lag_168h_price_return_x_lag_24h_volume_return', 'lag_168h_price_return_x_lag_3h_volume_return', 'lag_168h_price_return_x_lag_6h_volume_return', 'lag_168h_price_return_x_rolling_std_48h', 'lag_168h_price_return_x_volume_ma_12h', 'lag_168h_price_return_x_volume_return_1h', 'lag_24h_price_return', 'lag_24h_price_return_x_Volume BTC', 'lag_24h_price_return_x_bband_width_20h', 'lag_24h_price_return_x_cmf_20h', 'lag_24h_price_return_x_lag_24h_volume_return', 'lag_24h_price_return_x_lag_3h_volume_return', 'lag_24h_price_return_x_rolling_kurt_24h', 'lag_24h_price_return_x_rolling_std_48h', 'lag_24h_price_return_x_rolling_std_6h', 'lag_24h_price_return_x_std12_div_std72', 'lag_24h_price_return_x_volume_div_ma_24h', 'lag_24h_price_return_x_volume_ma_12h', 'lag_24h_price_return_x_volume_return_1h', 'lag_24h_volume_return', 'lag_24h_volume_return_x_bband_width_20h', 'lag_24h_volume_return_x_rolling_kurt_24h', 'lag_24h_volume_return_x_rolling_std_48h', 'lag_24h_volume_return_x_rolling_std_6h', 'lag_3h_volume_return', 'lag_3h_volume_return_x_bband_width_20h', 'lag_3h_volume_return_x_rolling_std_168h', 'lag_3h_volume_return_x_rolling_std_48h', 'lag_3h_volume_return_x_rolling_std_6h', 'lag_3h_volume_return_x_std12_div_std72', 'lag_48h_price_return', 'lag_48h_price_return_x_Volume BTC', 'lag_48h_price_return_x_bband_width_20h', 'lag_48h_price_return_x_cmf_20h', 'lag_48h_price_return_x_lag_12h_volume_return', 'lag_48h_price_return_x_lag_3h_volume_return', 'lag_48h_price_return_x_lag_6h_volume_return', 'lag_48h_price_return_x_rolling_kurt_24h', 'lag_48h_price_return_x_rolling_std_48h', 'lag_48h_price_return_x_rolling_std_6h', 'lag_48h_price_return_x_std12_div_std72', 'lag_48h_price_return_x_volume_ma_12h', 'lag_48h_price_return_x_volume_return_1h', 'lag_6h_volume_return', 'lag_6h_volume_return_x_bband_width_20h', 'lag_6h_volume_return_x_rolling_std_168h', 'lag_6h_volume_return_x_rolling_std_48h', 'lag_6h_volume_return_x_rolling_std_6h', 'lag_6h_volume_return_x_std12_div_std72', 'lag_72h_price_return', 'lag_72h_price_return_x_Volume BTC', 'lag_72h_price_return_x_bband_width_20h', 'lag_72h_price_return_x_lag_24h_volume_return', 'lag_72h_price_return_x_rolling_std_48h', 'lag_72h_price_return_x_rolling_std_6h', 'lag_72h_price_return_x_std12_div_std72', 'lag_72h_price_return_x_volume_div_ma_24h', 'lag_72h_price_return_x_volume_ma_12h', 'lag_72h_price_return_x_volume_return_1h', 'macd_hist', 'macd_hist_x_bband_width_20h', 'macd_hist_x_lag_12h_volume_return', 'macd_hist_x_lag_24h_volume_return', 'macd_hist_x_lag_3h_volume_return', 'macd_hist_x_lag_6h_volume_return', 'macd_hist_x_rolling_std_168h', 'macd_hist_x_rolling_std_48h', 'macd_hist_x_std12_div_std72', 'macd_hist_x_volume_ma_168h', 'macd_hist_x_volume_return_1h', 'macd_signal', 'macd_signal_x_Volume BTC', 'macd_signal_x_bband_width_20h', 'macd_signal_x_lag_12h_volume_return', 'macd_signal_x_lag_3h_volume_return', 'macd_signal_x_lag_6h_volume_return', 'macd_signal_x_rolling_std_168h', 'macd_signal_x_volume_ma_168h', 'macd_signal_x_volume_return_1h', 'rolling_std_168h_log1p', 'rolling_std_168h_sqrt', 'rolling_std_3h_sq_sqrt', 'rolling_std_48h', 'rolling_std_48h_log1p', 'rolling_std_48h_sqrt', 'rolling_std_6h', 'rolling_std_6h_log1p', 'rolling_std_6h_sqrt', 'volume_div_ma_24h', 'volume_div_ma_24h_x_bband_width_20h', 'volume_div_ma_24h_x_rolling_std_48h', 'volume_div_ma_24h_x_rolling_std_6h', 'volume_div_ma_24h_x_std12_div_std72', 'volume_ma_12h', 'volume_ma_12h_log1p', 'volume_ma_12h_x_rolling_std_168h', 'volume_ma_12h_x_rolling_std_48h', 'volume_ma_12h_x_std12_div_std72', 'volume_ma_168h', 'volume_ma_168h_log1p', 'volume_ma_168h_x_bband_width_20h', 'volume_ma_168h_x_rolling_std_168h', 'volume_ma_168h_x_rolling_std_6h', 'volume_return_1h_sq', 'volume_return_1h_x_bband_width_20h', 'volume_return_1h_x_rolling_std_168h', 'volume_return_1h_x_rolling_std_48h', 'volume_return_1h_x_rolling_std_6h', 'volume_return_1h_x_std12_div_std72']\n",
    "Features remaining after VIF check: 123\n",
    "--- VIF calculation finished. ---\n",
    "\n",
    "--- 9. Final Selection Summary (Post-Advanced Engineering) ---\n",
    "Features after initial VIF:              58\n",
    "Features after advanced eng+transform: 271\n",
    "Features after final VIF (6.9):      123\n",
    "\n",
    "Final list of selected feature names (after second VIF pass):\n",
    "  1. Volume BTC_x_rolling_std_168h\n",
    "  2. Volume BTC_x_std12_div_std72\n",
    "  3. Volume USD\n",
    "  4. cci_20h_sq\n",
    "  5. cci_20h_x_Volume BTC\n",
    "  6. cci_20h_x_cmf_20h\n",
    "  7. cci_20h_x_lag_24h_volume_return\n",
    "  8. cci_20h_x_lag_3h_volume_return\n",
    "  9. cci_20h_x_rolling_kurt_24h\n",
    "  10. cci_20h_x_rolling_std_168h\n",
    "  11. cci_20h_x_rolling_std_48h\n",
    "  12. cci_20h_x_std12_div_std72\n",
    "  13. cci_20h_x_volume_div_ma_24h\n",
    "  14. cci_20h_x_volume_ma_168h\n",
    "  15. close_pos_in_range\n",
    "  16. cmf_20h\n",
    "  17. cmf_20h_x_bband_width_20h\n",
    "  18. cmf_20h_x_rolling_kurt_24h\n",
    "  19. cmf_20h_x_rolling_std_168h\n",
    "  20. cmf_20h_x_rolling_std_6h\n",
    "  21. cmf_20h_x_std12_div_std72\n",
    "  22. day_0\n",
    "  23. day_1\n",
    "  24. day_2\n",
    "  25. day_4\n",
    "  26. day_5\n",
    "  27. day_6\n",
    "  28. hour_0\n",
    "  29. hour_1\n",
    "  30. hour_10\n",
    "  31. hour_11\n",
    "  32. hour_12\n",
    "  33. hour_13\n",
    "  34. hour_14\n",
    "  35. hour_15\n",
    "  36. hour_16\n",
    "  37. hour_17\n",
    "  38. hour_18\n",
    "  39. hour_19\n",
    "  40. hour_2\n",
    "  41. hour_20\n",
    "  42. hour_21\n",
    "  43. hour_22\n",
    "  44. hour_23\n",
    "  45. hour_3\n",
    "  46. hour_4\n",
    "  47. hour_5\n",
    "  48. hour_6\n",
    "  49. hour_8\n",
    "  50. hour_9\n",
    "  51. lag_12h_price_return_sq\n",
    "  52. lag_12h_price_return_x_cmf_20h\n",
    "  53. lag_12h_price_return_x_rolling_kurt_24h\n",
    "  54. lag_12h_price_return_x_rolling_std_168h\n",
    "  55. lag_12h_price_return_x_volume_ma_168h\n",
    "  56. lag_12h_volume_return\n",
    "  57. lag_168h_price_return_sq\n",
    "  58. lag_168h_price_return_x_Volume BTC\n",
    "  59. lag_168h_price_return_x_bband_width_20h\n",
    "  60. lag_168h_price_return_x_cmf_20h\n",
    "  61. lag_168h_price_return_x_rolling_kurt_24h\n",
    "  62. lag_168h_price_return_x_rolling_std_168h\n",
    "  63. lag_168h_price_return_x_rolling_std_6h\n",
    "  64. lag_168h_price_return_x_std12_div_std72\n",
    "  65. lag_168h_price_return_x_volume_div_ma_24h\n",
    "  66. lag_168h_price_return_x_volume_ma_168h\n",
    "  67. lag_24h_price_return_sq\n",
    "  68. lag_24h_price_return_x_lag_12h_volume_return\n",
    "  69. lag_24h_price_return_x_lag_6h_volume_return\n",
    "  70. lag_24h_price_return_x_rolling_std_168h\n",
    "  71. lag_24h_price_return_x_volume_ma_168h\n",
    "  72. lag_24h_volume_return_x_rolling_std_168h\n",
    "  73. lag_24h_volume_return_x_std12_div_std72\n",
    "  74. lag_3h_volume_return_x_rolling_kurt_24h\n",
    "  75. lag_48h_price_return_sq\n",
    "  76. lag_48h_price_return_x_lag_24h_volume_return\n",
    "  77. lag_48h_price_return_x_rolling_std_168h\n",
    "  78. lag_48h_price_return_x_volume_div_ma_24h\n",
    "  79. lag_48h_price_return_x_volume_ma_168h\n",
    "  80. lag_6h_volume_return_x_rolling_kurt_24h\n",
    "  81. lag_72h_price_return_sq\n",
    "  82. lag_72h_price_return_x_cmf_20h\n",
    "  83. lag_72h_price_return_x_lag_12h_volume_return\n",
    "  84. lag_72h_price_return_x_lag_3h_volume_return\n",
    "  85. lag_72h_price_return_x_lag_6h_volume_return\n",
    "  86. lag_72h_price_return_x_rolling_kurt_24h\n",
    "  87. lag_72h_price_return_x_rolling_std_168h\n",
    "  88. lag_72h_price_return_x_volume_ma_168h\n",
    "  89. macd_hist_sq\n",
    "  90. macd_hist_x_Volume BTC\n",
    "  91. macd_hist_x_cmf_20h\n",
    "  92. macd_hist_x_rolling_kurt_24h\n",
    "  93. macd_hist_x_rolling_std_6h\n",
    "  94. macd_hist_x_volume_div_ma_24h\n",
    "  95. macd_hist_x_volume_ma_12h\n",
    "  96. macd_signal_sq\n",
    "  97. macd_signal_x_cmf_20h\n",
    "  98. macd_signal_x_lag_24h_volume_return\n",
    "  99. macd_signal_x_rolling_kurt_24h\n",
    "  100. macd_signal_x_rolling_std_48h\n",
    "  101. macd_signal_x_rolling_std_6h\n",
    "  102. macd_signal_x_std12_div_std72\n",
    "  103. macd_signal_x_volume_div_ma_24h\n",
    "  104. macd_signal_x_volume_ma_12h\n",
    "  105. rolling_kurt_24h\n",
    "  106. rolling_skew_24h\n",
    "  107. rolling_std_168h\n",
    "  108. rolling_std_3h_sq\n",
    "  109. rolling_std_6h_div_rolling_std_48h\n",
    "  110. std12_div_std72\n",
    "  111. volume_btc_x_range\n",
    "  112. volume_btc_x_range_log1p\n",
    "  113. volume_div_ma_24h_sq\n",
    "  114. volume_div_ma_24h_x_rolling_kurt_24h\n",
    "  115. volume_div_ma_24h_x_rolling_std_168h\n",
    "  116. volume_ma_12h_x_bband_width_20h\n",
    "  117. volume_ma_12h_x_rolling_kurt_24h\n",
    "  118. volume_ma_12h_x_rolling_std_6h\n",
    "  119. volume_ma_168h_x_rolling_kurt_24h\n",
    "  120. volume_ma_168h_x_rolling_std_48h\n",
    "  121. volume_ma_168h_x_std12_div_std72\n",
    "  122. volume_return_1h\n",
    "  123. volume_return_1h_x_rolling_kurt_24h\n",
    "\n",
    "Total final selected features: 123\n",
    "\n",
    "Advanced feature engineering and selection script finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
