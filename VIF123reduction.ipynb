{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VIF Feature Selection Script ---\n",
      "\n",
      "--- 1. Data Loading & Initial Prep ---\n",
      "Loading data from: C:\\Users\\mason\\AVP\\BTCUSDrec.csv\n",
      "Raw data loaded. Shape: (15177, 9)\n",
      "Initial data prep done. Shape: (15177, 7)\n",
      "\n",
      "--- 2. Feature Engineering (Generating 123 Features) ---\n",
      "Starting calculation of selected 123 features...\n",
      "  Calculating prerequisites...\n",
      "  Calculating final derived features...\n",
      "  Assembling final dataframe...\n",
      "Selected feature calculation finished. Returning 15177 rows, 129 total columns (123 features). Took 0.14s.\n",
      "Feature calculation completed in 0.15 seconds.\n",
      "\n",
      "--- 3. Preparing Data for VIF (Using 123 features) ---\n",
      "  Imputing NaNs using median strategy...\n",
      "  NaN count after imputation: 0\n",
      "  Adding constant for VIF calculation...\n",
      "\n",
      "--- 4. Iterative VIF Calculation ---\n",
      "Starting VIF filtering with threshold 1.73...\n",
      "  Dropping 'lag_48h_price_return_x_lag_24h_volume_return' with VIF: 418.5294\n",
      "  Dropping 'cci_20h_x_lag_24h_volume_return' with VIF: 61.6671\n",
      "  Dropping 'lag_24h_volume_return_x_rolling_std_168h' with VIF: 46.0606\n",
      "  Dropping 'lag_72h_price_return_x_rolling_std_168h' with VIF: 31.5633\n",
      "  Dropping 'lag_12h_price_return_x_volume_ma_168h' with VIF: 20.8058\n",
      "  Dropping 'lag_48h_price_return_x_volume_ma_168h' with VIF: 18.8370\n",
      "  Dropping 'lag_24h_price_return_x_rolling_std_168h' with VIF: 15.2237\n",
      "  Dropping 'lag_168h_price_return_x_volume_ma_168h' with VIF: 14.8261\n",
      "  Dropping 'rolling_kurt_24h' with VIF: 13.7497\n",
      "  Dropping 'lag_12h_price_return_x_cmf_20h' with VIF: 13.0167\n",
      "  Dropping 'Volume BTC_x_rolling_std_168h' with VIF: 12.8870\n",
      "  Dropping 'cci_20h_x_volume_div_ma_24h' with VIF: 12.3210\n",
      "  Dropping 'cci_20h_x_volume_ma_168h' with VIF: 11.1649\n",
      "  Dropping 'Volume USD' with VIF: 9.4667\n",
      "  Dropping 'macd_hist_x_Volume BTC' with VIF: 9.1450\n",
      "  Dropping 'macd_signal_x_volume_ma_12h' with VIF: 9.0771\n",
      "  Dropping 'cmf_20h_x_bband_width_20h' with VIF: 8.3082\n",
      "  Dropping 'lag_48h_price_return_x_volume_div_ma_24h' with VIF: 7.9100\n",
      "  Dropping 'macd_signal_x_lag_24h_volume_return' with VIF: 7.6420\n",
      "  Dropping 'volume_div_ma_24h_x_rolling_kurt_24h' with VIF: 7.4772\n",
      "  Dropping 'cmf_20h_x_rolling_std_6h' with VIF: 7.3663\n",
      "  Dropping 'lag_168h_price_return_x_Volume BTC' with VIF: 7.1025\n",
      "  Dropping 'cmf_20h' with VIF: 7.0141\n",
      "  Dropping 'lag_12h_price_return_x_rolling_kurt_24h' with VIF: 6.9879\n",
      "  Dropping 'volume_ma_12h_x_bband_width_20h' with VIF: 6.8100\n",
      "  Dropping 'std12_div_std72' with VIF: 6.7761\n",
      "  Dropping 'lag_24h_price_return_x_lag_6h_volume_return' with VIF: 6.7755\n",
      "  Dropping 'macd_signal_x_rolling_std_48h' with VIF: 6.6319\n",
      "  Dropping 'macd_signal_x_std12_div_std72' with VIF: 6.2944\n",
      "  Dropping 'volume_btc_x_range_log1p' with VIF: 5.9025\n",
      "  Dropping 'cci_20h_x_rolling_std_168h' with VIF: 5.8629\n",
      "  Dropping 'lag_168h_price_return_x_bband_width_20h' with VIF: 5.2773\n",
      "  Dropping 'macd_hist_x_volume_ma_12h' with VIF: 5.1589\n",
      "  Dropping 'cci_20h_x_Volume BTC' with VIF: 4.9910\n",
      "  Dropping 'lag_72h_price_return_x_rolling_kurt_24h' with VIF: 4.9699\n",
      "  Dropping 'lag_168h_price_return_x_rolling_std_168h' with VIF: 4.6777\n",
      "  Dropping 'Volume BTC_x_std12_div_std72' with VIF: 4.6460\n",
      "  Dropping 'lag_72h_price_return_x_cmf_20h' with VIF: 4.4408\n",
      "  Dropping 'volume_ma_168h_x_rolling_std_48h' with VIF: 4.3978\n",
      "  Dropping 'cci_20h_x_rolling_kurt_24h' with VIF: 4.0131\n",
      "  Dropping 'lag_168h_price_return_x_rolling_std_6h' with VIF: 3.9530\n",
      "  Dropping 'lag_24h_price_return_x_lag_12h_volume_return' with VIF: 3.7431\n",
      "  Dropping 'lag_48h_price_return_sq' with VIF: 3.7225\n",
      "  Dropping 'volume_div_ma_24h_sq' with VIF: 3.6313\n",
      "  Dropping 'lag_12h_price_return_sq' with VIF: 3.5417\n",
      "  Dropping 'cmf_20h_x_std12_div_std72' with VIF: 3.5244\n",
      "  Dropping 'lag_48h_price_return_x_rolling_std_168h' with VIF: 3.4764\n",
      "  Dropping 'lag_24h_price_return_x_volume_ma_168h' with VIF: 3.4162\n",
      "  Dropping 'volume_return_1h_x_rolling_kurt_24h' with VIF: 3.3411\n",
      "  Dropping 'volume_ma_12h_x_rolling_std_6h' with VIF: 3.2643\n",
      "  Dropping 'lag_12h_price_return_x_rolling_std_168h' with VIF: 3.1447\n",
      "  Dropping 'macd_signal_x_volume_div_ma_24h' with VIF: 3.0212\n",
      "  Dropping 'macd_hist_x_volume_div_ma_24h' with VIF: 2.9776\n",
      "  Dropping 'macd_signal_sq' with VIF: 2.9293\n",
      "  Dropping 'volume_ma_12h_x_rolling_kurt_24h' with VIF: 2.9027\n",
      "  Dropping 'macd_hist_x_cmf_20h' with VIF: 2.8663\n",
      "  Dropping 'lag_168h_price_return_x_std12_div_std72' with VIF: 2.7145\n",
      "  Dropping 'volume_div_ma_24h_x_rolling_std_168h' with VIF: 2.6137\n",
      "  Dropping 'macd_signal_x_rolling_kurt_24h' with VIF: 2.5708\n",
      "  Dropping 'lag_168h_price_return_sq' with VIF: 2.5161\n",
      "  Dropping 'cci_20h_x_rolling_std_48h' with VIF: 2.4787\n",
      "  Dropping 'lag_72h_price_return_x_lag_6h_volume_return' with VIF: 2.4346\n",
      "  Dropping 'lag_24h_price_return_sq' with VIF: 2.2570\n",
      "  Dropping 'rolling_std_6h_div_rolling_std_48h' with VIF: 2.1437\n",
      "  Dropping 'lag_72h_price_return_x_volume_ma_168h' with VIF: 2.1240\n",
      "  Dropping 'macd_hist_x_rolling_kurt_24h' with VIF: 1.9974\n",
      "  Dropping 'hour_15' with VIF: 1.9873\n",
      "  Dropping 'lag_3h_volume_return_x_rolling_kurt_24h' with VIF: 1.9047\n",
      "  Dropping 'cci_20h_x_std12_div_std72' with VIF: 1.8363\n",
      "  Dropping 'day_0' with VIF: 1.8165\n",
      "  Dropping 'cci_20h_sq' with VIF: 1.7601\n",
      "  All remaining features have VIF <= 1.73.\n",
      "\n",
      "--- 5. VIF Selection Results ---\n",
      "VIF Threshold: 1.73\n",
      "Original number of features considered: 123\n",
      "Number of features dropped: 71\n",
      "Number of features remaining: 52\n",
      "\n",
      "Final selected features (VIF < 1.73):\n",
      "SELECTED_FEATURE_NAMES_VIF_FILTERED = [\n",
      "    'cci_20h_x_cmf_20h',\n",
      "    'cci_20h_x_lag_3h_volume_return',\n",
      "    'close_pos_in_range',\n",
      "    'cmf_20h_x_rolling_kurt_24h',\n",
      "    'cmf_20h_x_rolling_std_168h',\n",
      "    'day_1',\n",
      "    'day_2',\n",
      "    'day_4',\n",
      "    'day_5',\n",
      "    'day_6',\n",
      "    'hour_0',\n",
      "    'hour_1',\n",
      "    'hour_10',\n",
      "    'hour_11',\n",
      "    'hour_12',\n",
      "    'hour_13',\n",
      "    'hour_14',\n",
      "    'hour_16',\n",
      "    'hour_17',\n",
      "    'hour_18',\n",
      "    'hour_19',\n",
      "    'hour_2',\n",
      "    'hour_20',\n",
      "    'hour_21',\n",
      "    'hour_22',\n",
      "    'hour_23',\n",
      "    'hour_3',\n",
      "    'hour_4',\n",
      "    'hour_5',\n",
      "    'hour_6',\n",
      "    'hour_8',\n",
      "    'hour_9',\n",
      "    'lag_12h_volume_return',\n",
      "    'lag_168h_price_return_x_cmf_20h',\n",
      "    'lag_168h_price_return_x_rolling_kurt_24h',\n",
      "    'lag_168h_price_return_x_volume_div_ma_24h',\n",
      "    'lag_24h_volume_return_x_std12_div_std72',\n",
      "    'lag_6h_volume_return_x_rolling_kurt_24h',\n",
      "    'lag_72h_price_return_sq',\n",
      "    'lag_72h_price_return_x_lag_12h_volume_return',\n",
      "    'lag_72h_price_return_x_lag_3h_volume_return',\n",
      "    'macd_hist_sq',\n",
      "    'macd_hist_x_rolling_std_6h',\n",
      "    'macd_signal_x_cmf_20h',\n",
      "    'macd_signal_x_rolling_std_6h',\n",
      "    'rolling_skew_24h',\n",
      "    'rolling_std_168h',\n",
      "    'rolling_std_3h_sq',\n",
      "    'volume_btc_x_range',\n",
      "    'volume_ma_168h_x_rolling_kurt_24h',\n",
      "    'volume_ma_168h_x_std12_div_std72',\n",
      "    'volume_return_1h',\n",
      "]\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pandas_ta as ta # Make sure this is imported if needed by calculate_selected_features\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore') # General suppression\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Data Loading\n",
    "CSV_FILE_PATH = r'C:\\Users\\mason\\AVP\\BTCUSDrec.csv' # Use raw string for Windows paths\n",
    "SYMBOL_NAME = 'BTCUSD' # Define the symbol represented in the CSV\n",
    "\n",
    "# Feature Selection List (The 123 features you want to filter FROM)\n",
    "# This list should ideally be identical to the one used in your main script's config\n",
    "SELECTED_FEATURE_NAMES_INPUT = [\n",
    "    'Volume BTC_x_rolling_std_168h', 'Volume BTC_x_std12_div_std72', 'Volume USD',\n",
    "    'cci_20h_sq', 'cci_20h_x_Volume BTC', 'cci_20h_x_cmf_20h',\n",
    "    'cci_20h_x_lag_24h_volume_return', 'cci_20h_x_lag_3h_volume_return',\n",
    "    'cci_20h_x_rolling_kurt_24h', 'cci_20h_x_rolling_std_168h',\n",
    "    'cci_20h_x_rolling_std_48h', 'cci_20h_x_std12_div_std72',\n",
    "    'cci_20h_x_volume_div_ma_24h', 'cci_20h_x_volume_ma_168h',\n",
    "    'close_pos_in_range', 'cmf_20h', 'cmf_20h_x_bband_width_20h',\n",
    "    'cmf_20h_x_rolling_kurt_24h', 'cmf_20h_x_rolling_std_168h',\n",
    "    'cmf_20h_x_rolling_std_6h', 'cmf_20h_x_std12_div_std72', 'day_0', 'day_1',\n",
    "    'day_2', 'day_4', 'day_5', 'day_6', 'hour_0', 'hour_1', 'hour_10',\n",
    "    'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "    'hour_17', 'hour_18', 'hour_19', 'hour_2', 'hour_20', 'hour_21',\n",
    "    'hour_22', 'hour_23', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_8',\n",
    "    'hour_9', 'lag_12h_price_return_sq', 'lag_12h_price_return_x_cmf_20h',\n",
    "    'lag_12h_price_return_x_rolling_kurt_24h',\n",
    "    'lag_12h_price_return_x_rolling_std_168h',\n",
    "    'lag_12h_price_return_x_volume_ma_168h', 'lag_12h_volume_return',\n",
    "    'lag_168h_price_return_sq', 'lag_168h_price_return_x_Volume BTC',\n",
    "    'lag_168h_price_return_x_bband_width_20h', 'lag_168h_price_return_x_cmf_20h',\n",
    "    'lag_168h_price_return_x_rolling_kurt_24h',\n",
    "    'lag_168h_price_return_x_rolling_std_168h',\n",
    "    'lag_168h_price_return_x_rolling_std_6h',\n",
    "    'lag_168h_price_return_x_std12_div_std72',\n",
    "    'lag_168h_price_return_x_volume_div_ma_24h',\n",
    "    'lag_168h_price_return_x_volume_ma_168h', 'lag_24h_price_return_sq',\n",
    "    'lag_24h_price_return_x_lag_12h_volume_return',\n",
    "    'lag_24h_price_return_x_lag_6h_volume_return',\n",
    "    'lag_24h_price_return_x_rolling_std_168h',\n",
    "    'lag_24h_price_return_x_volume_ma_168h',\n",
    "    'lag_24h_volume_return_x_rolling_std_168h',\n",
    "    'lag_24h_volume_return_x_std12_div_std72',\n",
    "    'lag_3h_volume_return_x_rolling_kurt_24h', 'lag_48h_price_return_sq',\n",
    "    'lag_48h_price_return_x_lag_24h_volume_return',\n",
    "    'lag_48h_price_return_x_rolling_std_168h',\n",
    "    'lag_48h_price_return_x_volume_div_ma_24h',\n",
    "    'lag_48h_price_return_x_volume_ma_168h',\n",
    "    'lag_6h_volume_return_x_rolling_kurt_24h', 'lag_72h_price_return_sq',\n",
    "    'lag_72h_price_return_x_cmf_20h',\n",
    "    'lag_72h_price_return_x_lag_12h_volume_return',\n",
    "    'lag_72h_price_return_x_lag_3h_volume_return',\n",
    "    'lag_72h_price_return_x_lag_6h_volume_return',\n",
    "    'lag_72h_price_return_x_rolling_kurt_24h',\n",
    "    'lag_72h_price_return_x_rolling_std_168h',\n",
    "    'lag_72h_price_return_x_volume_ma_168h', 'macd_hist_sq',\n",
    "    'macd_hist_x_Volume BTC', 'macd_hist_x_cmf_20h',\n",
    "    'macd_hist_x_rolling_kurt_24h', 'macd_hist_x_rolling_std_6h',\n",
    "    'macd_hist_x_volume_div_ma_24h', 'macd_hist_x_volume_ma_12h',\n",
    "    'macd_signal_sq', 'macd_signal_x_cmf_20h',\n",
    "    'macd_signal_x_lag_24h_volume_return', 'macd_signal_x_rolling_kurt_24h',\n",
    "    'macd_signal_x_rolling_std_48h', 'macd_signal_x_rolling_std_6h',\n",
    "    'macd_signal_x_std12_div_std72', 'macd_signal_x_volume_div_ma_24h',\n",
    "    'macd_signal_x_volume_ma_12h', 'rolling_kurt_24h', 'rolling_skew_24h',\n",
    "    'rolling_std_168h', 'rolling_std_3h_sq',\n",
    "    'rolling_std_6h_div_rolling_std_48h', 'std12_div_std72',\n",
    "    'volume_btc_x_range', 'volume_btc_x_range_log1p', 'volume_div_ma_24h_sq',\n",
    "    'volume_div_ma_24h_x_rolling_kurt_24h',\n",
    "    'volume_div_ma_24h_x_rolling_std_168h',\n",
    "    'volume_ma_12h_x_bband_width_20h', 'volume_ma_12h_x_rolling_kurt_24h',\n",
    "    'volume_ma_12h_x_rolling_std_6h', 'volume_ma_168h_x_rolling_kurt_24h',\n",
    "    'volume_ma_168h_x_rolling_std_48h', 'volume_ma_168h_x_std12_div_std72',\n",
    "    'volume_return_1h', 'volume_return_1h_x_rolling_kurt_24h'\n",
    "]\n",
    "\n",
    "# VIF Threshold\n",
    "VIF_THRESHOLD = 1.73\n",
    "\n",
    "# --- Feature Engineering Function (Paste your updated 123-feature version here) ---\n",
    "# --- Needs to be defined before being called in __main__                   ---\n",
    "def calculate_selected_features(df, symbol):\n",
    "    \"\"\"Calculates only the 123 pre-selected features and their prerequisites.\"\"\"\n",
    "    print(\"Starting calculation of selected 123 features...\")\n",
    "    start_time = time.time()\n",
    "    if df is None or len(df) < 3:\n",
    "        print(\"Error: Input DataFrame is None or too small.\")\n",
    "        return pd.DataFrame()\n",
    "    df = df.copy()\n",
    "    df['symbol'] = symbol\n",
    "\n",
    "    # --- Timestamp and Index ---\n",
    "    if 'timestamp' not in df.columns:\n",
    "        print(\"Error: 'timestamp' column not found.\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting timestamp to datetime: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    df = df.sort_values('timestamp').dropna(subset=['timestamp'])\n",
    "    df = df.set_index('timestamp', drop=False)\n",
    "\n",
    "    # --- Volume Columns (Standardize internal naming) ---\n",
    "    # Use original names from CSV loading step for consistency with feature list\n",
    "    if 'Volume BTC' in df.columns:\n",
    "        df['volume_btc'] = df['Volume BTC'] # Internal standard name\n",
    "    elif 'volume_btc' in df.columns:\n",
    "        df['Volume BTC'] = df['volume_btc'] # Ensure original name exists if passed\n",
    "    else:\n",
    "        df['volume_btc'] = 0\n",
    "        df['Volume BTC'] = 0 # Add original name column if missing\n",
    "    if 'Volume USD' in df.columns:\n",
    "        # Keep 'Volume USD' as it is requested directly\n",
    "        pass\n",
    "    elif 'volume_usd' in df.columns:\n",
    "         df['Volume USD'] = df['volume_usd'] # Ensure original name exists if passed\n",
    "    else:\n",
    "        df['Volume USD'] = 0 # Add original name column if missing\n",
    "\n",
    "\n",
    "    # --- Basic Checks (OHLC) ---\n",
    "    required_ohlc = ['open', 'high', 'low', 'close']\n",
    "    all_ohlc_present = True\n",
    "    for col in required_ohlc:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: Required column '{col}' not found.\")\n",
    "            all_ohlc_present = False\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    if not all_ohlc_present: return pd.DataFrame()\n",
    "\n",
    "    if df[required_ohlc].isnull().any().any():\n",
    "        print(f\"Warning: NaNs found in required OHLC columns. Rows before drop: {len(df)}\")\n",
    "        df = df.dropna(subset=required_ohlc)\n",
    "        print(f\"Rows after dropping NaNs in OHLC: {len(df)}\")\n",
    "    if df.empty:\n",
    "        print(\"Error: DataFrame empty after dropping OHLC NaNs.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 1. Calculate Prerequisites ---\n",
    "    print(\"  Calculating prerequisites...\")\n",
    "    min_periods_base = 2\n",
    "\n",
    "    # Basic Returns/Changes\n",
    "    df['price_return_1h_temp'] = df['close'].pct_change() # Needed for skew/kurt\n",
    "    df['volume_return_1h'] = df['volume_btc'].pct_change()\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['price_range_pct_temp'] = (df['high'] - df['low']) / df['low'].replace(0, np.nan) # Needed for volume_btc_x_range\n",
    "\n",
    "    # Lags\n",
    "    for hours in [12, 24, 48, 72, 168]: df[f'lag_{hours}h_price_return'] = df['close'].pct_change(periods=hours)\n",
    "    for hours in [3, 6, 12, 24]: df[f'lag_{hours}h_volume_return'] = df['volume_btc'].pct_change(periods=hours)\n",
    "\n",
    "    # Rolling Stats (Only calculate those needed)\n",
    "    needed_rolling_std_hours = [6, 48, 168] # 48 added\n",
    "    for hours in needed_rolling_std_hours:\n",
    "        if len(df) >= hours: df[f'rolling_std_{hours}h'] = df['close'].rolling(window=hours, min_periods=min_periods_base).std()\n",
    "        else: df[f'rolling_std_{hours}h'] = np.nan\n",
    "    # Intermediates for ratios/squares\n",
    "    if len(df) >= 12: df['rolling_std_12h_temp'] = df['close'].rolling(window=12, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_12h_temp'] = np.nan\n",
    "    if len(df) >= 72: df['rolling_std_72h_temp'] = df['close'].rolling(window=72, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_72h_temp'] = np.nan\n",
    "    if len(df) >= 3: df['rolling_std_3h_temp'] = df['close'].rolling(window=3, min_periods=min_periods_base).std()\n",
    "    else: df['rolling_std_3h_temp'] = np.nan\n",
    "    # Ensure rolling_std_48h exists for division (it's calculated above now)\n",
    "\n",
    "    # Skew/Kurtosis\n",
    "    if len(df) >= 24 and 'price_return_1h_temp' in df.columns:\n",
    "        df['rolling_skew_24h'] = df['price_return_1h_temp'].rolling(window=24, min_periods=24).skew()\n",
    "        df['rolling_kurt_24h'] = df['price_return_1h_temp'].rolling(window=24, min_periods=24).kurt()\n",
    "    else:\n",
    "        df['rolling_skew_24h'] = np.nan\n",
    "        df['rolling_kurt_24h'] = np.nan\n",
    "\n",
    "    # Volume MAs and Ratios\n",
    "    needed_vol_ma_hours = [12, 168]\n",
    "    for hours in needed_vol_ma_hours:\n",
    "        if len(df) >= hours: df[f'volume_ma_{hours}h'] = df['volume_btc'].rolling(window=hours, min_periods=min_periods_base).mean()\n",
    "        else: df[f'volume_ma_{hours}h'] = np.nan\n",
    "    # Need MA24 for volume_div_ma_24h\n",
    "    if len(df) >= 24: df['volume_ma_24h_temp'] = df['volume_btc'].rolling(window=24, min_periods=min_periods_base).mean()\n",
    "    else: df['volume_ma_24h_temp'] = np.nan\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['volume_div_ma_24h'] = df['volume_btc'] / df['volume_ma_24h_temp'].replace(0, np.nan)\n",
    "\n",
    "    # MACD Components\n",
    "    if len(df) >= 35: # Need 26 for base + 9 for signal\n",
    "        ema_12 = df['close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "        ema_26 = df['close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "        df['macd_temp'] = ema_12 - ema_26\n",
    "        df['macd_signal'] = df['macd_temp'].ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "        df['macd_hist'] = df['macd_temp'] - df['macd_signal']\n",
    "    else:\n",
    "        df['macd_temp'] = np.nan\n",
    "        df['macd_signal'] = np.nan\n",
    "        df['macd_hist'] = np.nan\n",
    "\n",
    "    # TA-Lib Indicators (CCI, CMF, BBands Width)\n",
    "    ta_df = df.rename(columns={'volume_btc': 'volume'}, errors='ignore') # Use internal standard name\n",
    "    if all(c in ta_df.columns for c in ['high', 'low', 'close']):\n",
    "        try: df['cci_20h'] = ta_df.ta.cci(length=20)\n",
    "        except Exception as e: print(f\" Warning: CCI calc failed: {e}\"); df['cci_20h'] = np.nan\n",
    "\n",
    "        if 'volume' in ta_df.columns:\n",
    "             try: df['cmf_20h'] = ta_df.ta.cmf(length=20)\n",
    "             except Exception as e: print(f\" Warning: CMF calc failed: {e}\"); df['cmf_20h'] = np.nan\n",
    "        else: df['cmf_20h'] = np.nan\n",
    "\n",
    "        try:\n",
    "            bbands_df = ta_df.ta.bbands(length=20, std=2)\n",
    "            if bbands_df is not None: df['bband_width_20h'] = bbands_df.get(f'BBB_20_2.0', np.nan)\n",
    "            else: df['bband_width_20h'] = np.nan\n",
    "        except Exception as e: print(f\" Warning: BBand Width calc failed: {e}\"); df['bband_width_20h'] = np.nan\n",
    "    else:\n",
    "        df['cci_20h'], df['cmf_20h'], df['bband_width_20h'] = np.nan, np.nan, np.nan\n",
    "\n",
    "    # Position in Range\n",
    "    range_hl = df['high'] - df['low']\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        df['close_pos_in_range'] = ((df['close'] - df['low']) / range_hl.replace(0, np.nan)).fillna(0.5).replace([np.inf, -np.inf], 0.5)\n",
    "\n",
    "    # Ratio std12_div_std72\n",
    "    if 'rolling_std_12h_temp' in df.columns and 'rolling_std_72h_temp' in df.columns:\n",
    "         with np.errstate(divide='ignore', invalid='ignore'):\n",
    "             df['std12_div_std72'] = df['rolling_std_12h_temp'] / df['rolling_std_72h_temp'].replace(0, np.nan)\n",
    "    else: df['std12_div_std72'] = np.nan\n",
    "\n",
    "    # Interaction volume_btc_x_range\n",
    "    if 'price_range_pct_temp' in df.columns:\n",
    "         df['volume_btc_x_range'] = df['volume_btc'] * df['price_range_pct_temp']\n",
    "    else: df['volume_btc_x_range'] = np.nan\n",
    "\n",
    "    # Time Features\n",
    "    hour_of_day = df.index.hour\n",
    "    day_of_week = df.index.dayofweek\n",
    "    # Use full range for calculation, selection happens later\n",
    "    for hour in range(24): df[f'hour_{hour}'] = (hour_of_day == hour).astype(int)\n",
    "    for day in range(7): df[f'day_{day}'] = (day_of_week == day).astype(int)\n",
    "\n",
    "\n",
    "    # --- 2. Calculate Final Interaction and Transformation Features ---\n",
    "    print(\"  Calculating final derived features...\")\n",
    "    final_feature_dict = {} # Store results here\n",
    "\n",
    "    # Helper functions\n",
    "    def safe_multiply(col1_name, col2_name):\n",
    "        col1_actual = 'volume_btc' if col1_name == 'Volume BTC' else col1_name\n",
    "        col2_actual = 'volume_btc' if col2_name == 'Volume BTC' else col2_name\n",
    "        if col1_actual in df.columns and col2_actual in df.columns: return df[col1_actual] * df[col2_actual]\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    def safe_divide(col1_name, col2_name):\n",
    "         if col1_name in df.columns and col2_name in df.columns:\n",
    "              with np.errstate(divide='ignore', invalid='ignore'): return df[col1_name] / df[col2_name].replace(0, np.nan)\n",
    "         return pd.Series(np.nan, index=df.index)\n",
    "    def safe_sq(col_name):\n",
    "         if col_name in df.columns: return df[col_name]**2\n",
    "         return pd.Series(np.nan, index=df.index)\n",
    "    def safe_log1p(col_name):\n",
    "         if col_name in df.columns: return np.log1p(df[col_name].clip(lower=0))\n",
    "         return pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    # Add direct/base features that are part of the final list first\n",
    "    direct_features_in_final_list = [\n",
    "        'Volume USD', 'close_pos_in_range', 'cmf_20h', 'lag_12h_volume_return',\n",
    "        'rolling_kurt_24h', 'rolling_skew_24h', 'rolling_std_168h', 'std12_div_std72',\n",
    "        'volume_btc_x_range', 'volume_ma_12h', 'volume_ma_168h', 'volume_return_1h',\n",
    "        'macd_signal', 'macd_hist'\n",
    "    ]\n",
    "    # Use SELECTED_FEATURE_NAMES_INPUT here (or rename the global one)\n",
    "    direct_features_to_add = [f for f in direct_features_in_final_list if f in SELECTED_FEATURE_NAMES_INPUT]\n",
    "    for feat in direct_features_to_add:\n",
    "        if feat in df.columns: final_feature_dict[feat] = df[feat]\n",
    "\n",
    "    # Add requested Time features\n",
    "    for hour in range(24):\n",
    "         feat_name = f'hour_{hour}'\n",
    "         if feat_name in SELECTED_FEATURE_NAMES_INPUT: final_feature_dict[feat_name] = df[feat_name]\n",
    "    for day in range(7):\n",
    "         feat_name = f'day_{day}'\n",
    "         if feat_name in SELECTED_FEATURE_NAMES_INPUT: final_feature_dict[feat_name] = df[feat_name]\n",
    "\n",
    "    # Calculate Interaction/Transformation Features (Only if requested in SELECTED_FEATURE_NAMES_INPUT)\n",
    "    def add_if_requested(name, calculation):\n",
    "        if name in SELECTED_FEATURE_NAMES_INPUT: # Check against the input list\n",
    "            final_feature_dict[name] = calculation\n",
    "\n",
    "    add_if_requested('Volume BTC_x_rolling_std_168h', safe_multiply('Volume BTC', 'rolling_std_168h'))\n",
    "    add_if_requested('Volume BTC_x_std12_div_std72', safe_multiply('Volume BTC', 'std12_div_std72'))\n",
    "    add_if_requested('cci_20h_sq', safe_sq('cci_20h'))\n",
    "    add_if_requested('cci_20h_x_Volume BTC', safe_multiply('cci_20h', 'Volume BTC'))\n",
    "    add_if_requested('cci_20h_x_cmf_20h', safe_multiply('cci_20h', 'cmf_20h'))\n",
    "    add_if_requested('cci_20h_x_lag_24h_volume_return', safe_multiply('cci_20h', 'lag_24h_volume_return'))\n",
    "    add_if_requested('cci_20h_x_lag_3h_volume_return', safe_multiply('cci_20h', 'lag_3h_volume_return'))\n",
    "    add_if_requested('cci_20h_x_rolling_kurt_24h', safe_multiply('cci_20h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('cci_20h_x_rolling_std_168h', safe_multiply('cci_20h', 'rolling_std_168h'))\n",
    "    add_if_requested('cci_20h_x_rolling_std_48h', safe_multiply('cci_20h', 'rolling_std_48h'))\n",
    "    add_if_requested('cci_20h_x_std12_div_std72', safe_multiply('cci_20h', 'std12_div_std72'))\n",
    "    add_if_requested('cci_20h_x_volume_div_ma_24h', safe_multiply('cci_20h', 'volume_div_ma_24h'))\n",
    "    add_if_requested('cci_20h_x_volume_ma_168h', safe_multiply('cci_20h', 'volume_ma_168h'))\n",
    "    add_if_requested('cmf_20h_x_bband_width_20h', safe_multiply('cmf_20h', 'bband_width_20h'))\n",
    "    add_if_requested('cmf_20h_x_rolling_kurt_24h', safe_multiply('cmf_20h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('cmf_20h_x_rolling_std_168h', safe_multiply('cmf_20h', 'rolling_std_168h'))\n",
    "    add_if_requested('cmf_20h_x_rolling_std_6h', safe_multiply('cmf_20h', 'rolling_std_6h'))\n",
    "    add_if_requested('cmf_20h_x_std12_div_std72', safe_multiply('cmf_20h', 'std12_div_std72'))\n",
    "    add_if_requested('lag_12h_price_return_sq', safe_sq('lag_12h_price_return'))\n",
    "    add_if_requested('lag_12h_price_return_x_cmf_20h', safe_multiply('lag_12h_price_return', 'cmf_20h'))\n",
    "    add_if_requested('lag_12h_price_return_x_rolling_kurt_24h', safe_multiply('lag_12h_price_return', 'rolling_kurt_24h'))\n",
    "    add_if_requested('lag_12h_price_return_x_rolling_std_168h', safe_multiply('lag_12h_price_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_12h_price_return_x_volume_ma_168h', safe_multiply('lag_12h_price_return', 'volume_ma_168h'))\n",
    "    add_if_requested('lag_168h_price_return_sq', safe_sq('lag_168h_price_return'))\n",
    "    add_if_requested('lag_168h_price_return_x_Volume BTC', safe_multiply('lag_168h_price_return', 'Volume BTC'))\n",
    "    add_if_requested('lag_168h_price_return_x_bband_width_20h', safe_multiply('lag_168h_price_return', 'bband_width_20h'))\n",
    "    add_if_requested('lag_168h_price_return_x_cmf_20h', safe_multiply('lag_168h_price_return', 'cmf_20h'))\n",
    "    add_if_requested('lag_168h_price_return_x_rolling_kurt_24h', safe_multiply('lag_168h_price_return', 'rolling_kurt_24h'))\n",
    "    add_if_requested('lag_168h_price_return_x_rolling_std_168h', safe_multiply('lag_168h_price_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_168h_price_return_x_rolling_std_6h', safe_multiply('lag_168h_price_return', 'rolling_std_6h'))\n",
    "    add_if_requested('lag_168h_price_return_x_std12_div_std72', safe_multiply('lag_168h_price_return', 'std12_div_std72'))\n",
    "    add_if_requested('lag_168h_price_return_x_volume_div_ma_24h', safe_multiply('lag_168h_price_return', 'volume_div_ma_24h'))\n",
    "    add_if_requested('lag_168h_price_return_x_volume_ma_168h', safe_multiply('lag_168h_price_return', 'volume_ma_168h'))\n",
    "    add_if_requested('lag_24h_price_return_sq', safe_sq('lag_24h_price_return'))\n",
    "    add_if_requested('lag_24h_price_return_x_lag_12h_volume_return', safe_multiply('lag_24h_price_return', 'lag_12h_volume_return'))\n",
    "    add_if_requested('lag_24h_price_return_x_lag_6h_volume_return', safe_multiply('lag_24h_price_return', 'lag_6h_volume_return'))\n",
    "    add_if_requested('lag_24h_price_return_x_rolling_std_168h', safe_multiply('lag_24h_price_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_24h_price_return_x_volume_ma_168h', safe_multiply('lag_24h_price_return', 'volume_ma_168h'))\n",
    "    add_if_requested('lag_24h_volume_return_x_rolling_std_168h', safe_multiply('lag_24h_volume_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_24h_volume_return_x_std12_div_std72', safe_multiply('lag_24h_volume_return', 'std12_div_std72'))\n",
    "    add_if_requested('lag_3h_volume_return_x_rolling_kurt_24h', safe_multiply('lag_3h_volume_return', 'rolling_kurt_24h'))\n",
    "    add_if_requested('lag_48h_price_return_sq', safe_sq('lag_48h_price_return'))\n",
    "    add_if_requested('lag_48h_price_return_x_lag_24h_volume_return', safe_multiply('lag_48h_price_return', 'lag_24h_volume_return'))\n",
    "    add_if_requested('lag_48h_price_return_x_rolling_std_168h', safe_multiply('lag_48h_price_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_48h_price_return_x_volume_div_ma_24h', safe_multiply('lag_48h_price_return', 'volume_div_ma_24h'))\n",
    "    add_if_requested('lag_48h_price_return_x_volume_ma_168h', safe_multiply('lag_48h_price_return', 'volume_ma_168h'))\n",
    "    add_if_requested('lag_6h_volume_return_x_rolling_kurt_24h', safe_multiply('lag_6h_volume_return', 'rolling_kurt_24h'))\n",
    "    add_if_requested('lag_72h_price_return_sq', safe_sq('lag_72h_price_return'))\n",
    "    add_if_requested('lag_72h_price_return_x_cmf_20h', safe_multiply('lag_72h_price_return', 'cmf_20h'))\n",
    "    add_if_requested('lag_72h_price_return_x_lag_12h_volume_return', safe_multiply('lag_72h_price_return', 'lag_12h_volume_return'))\n",
    "    add_if_requested('lag_72h_price_return_x_lag_3h_volume_return', safe_multiply('lag_72h_price_return', 'lag_3h_volume_return'))\n",
    "    add_if_requested('lag_72h_price_return_x_lag_6h_volume_return', safe_multiply('lag_72h_price_return', 'lag_6h_volume_return'))\n",
    "    add_if_requested('lag_72h_price_return_x_rolling_kurt_24h', safe_multiply('lag_72h_price_return', 'rolling_kurt_24h'))\n",
    "    add_if_requested('lag_72h_price_return_x_rolling_std_168h', safe_multiply('lag_72h_price_return', 'rolling_std_168h'))\n",
    "    add_if_requested('lag_72h_price_return_x_volume_ma_168h', safe_multiply('lag_72h_price_return', 'volume_ma_168h'))\n",
    "    add_if_requested('macd_hist_sq', safe_sq('macd_hist'))\n",
    "    add_if_requested('macd_hist_x_Volume BTC', safe_multiply('macd_hist', 'Volume BTC'))\n",
    "    add_if_requested('macd_hist_x_cmf_20h', safe_multiply('macd_hist', 'cmf_20h'))\n",
    "    add_if_requested('macd_hist_x_rolling_kurt_24h', safe_multiply('macd_hist', 'rolling_kurt_24h'))\n",
    "    add_if_requested('macd_hist_x_rolling_std_6h', safe_multiply('macd_hist', 'rolling_std_6h'))\n",
    "    add_if_requested('macd_hist_x_volume_div_ma_24h', safe_multiply('macd_hist', 'volume_div_ma_24h'))\n",
    "    add_if_requested('macd_hist_x_volume_ma_12h', safe_multiply('macd_hist', 'volume_ma_12h'))\n",
    "    add_if_requested('macd_signal_sq', safe_sq('macd_signal'))\n",
    "    add_if_requested('macd_signal_x_cmf_20h', safe_multiply('macd_signal', 'cmf_20h'))\n",
    "    add_if_requested('macd_signal_x_lag_24h_volume_return', safe_multiply('macd_signal', 'lag_24h_volume_return'))\n",
    "    add_if_requested('macd_signal_x_rolling_kurt_24h', safe_multiply('macd_signal', 'rolling_kurt_24h'))\n",
    "    add_if_requested('macd_signal_x_rolling_std_48h', safe_multiply('macd_signal', 'rolling_std_48h'))\n",
    "    add_if_requested('macd_signal_x_rolling_std_6h', safe_multiply('macd_signal', 'rolling_std_6h'))\n",
    "    add_if_requested('macd_signal_x_std12_div_std72', safe_multiply('macd_signal', 'std12_div_std72'))\n",
    "    add_if_requested('macd_signal_x_volume_div_ma_24h', safe_multiply('macd_signal', 'volume_div_ma_24h'))\n",
    "    add_if_requested('macd_signal_x_volume_ma_12h', safe_multiply('macd_signal', 'volume_ma_12h'))\n",
    "    add_if_requested('rolling_std_3h_sq', safe_sq('rolling_std_3h_temp'))\n",
    "    add_if_requested('rolling_std_6h_div_rolling_std_48h', safe_divide('rolling_std_6h', 'rolling_std_48h'))\n",
    "    add_if_requested('volume_div_ma_24h_sq', safe_sq('volume_div_ma_24h'))\n",
    "    add_if_requested('volume_div_ma_24h_x_rolling_kurt_24h', safe_multiply('volume_div_ma_24h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('volume_div_ma_24h_x_rolling_std_168h', safe_multiply('volume_div_ma_24h', 'rolling_std_168h'))\n",
    "    add_if_requested('volume_ma_12h_x_bband_width_20h', safe_multiply('volume_ma_12h', 'bband_width_20h'))\n",
    "    add_if_requested('volume_ma_12h_x_rolling_kurt_24h', safe_multiply('volume_ma_12h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('volume_ma_12h_x_rolling_std_6h', safe_multiply('volume_ma_12h', 'rolling_std_6h'))\n",
    "    add_if_requested('volume_ma_168h_x_rolling_kurt_24h', safe_multiply('volume_ma_168h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('volume_ma_168h_x_rolling_std_48h', safe_multiply('volume_ma_168h', 'rolling_std_48h'))\n",
    "    add_if_requested('volume_ma_168h_x_std12_div_std72', safe_multiply('volume_ma_168h', 'std12_div_std72'))\n",
    "    add_if_requested('volume_return_1h_x_rolling_kurt_24h', safe_multiply('volume_return_1h', 'rolling_kurt_24h'))\n",
    "    add_if_requested('volume_btc_x_range_log1p', safe_log1p('volume_btc_x_range'))\n",
    "\n",
    "\n",
    "    # --- 3. Final Assembly and Cleanup ---\n",
    "    print(\"  Assembling final dataframe...\")\n",
    "    # Create DataFrame from the calculated features in the dictionary\n",
    "    df_final_features = pd.DataFrame(final_feature_dict, index=df.index)\n",
    "\n",
    "    # Combine essential columns from original df with calculated features\n",
    "    essential_cols = ['timestamp', 'symbol', 'open', 'high', 'low', 'close']\n",
    "    # Ensure essential columns exist before concatenation\n",
    "    essential_cols_present = [col for col in essential_cols if col in df.columns]\n",
    "    df_combined = pd.concat([df[essential_cols_present], df_final_features], axis=1)\n",
    "\n",
    "\n",
    "    # Define the list of columns to keep: essential + the globally defined SELECTED_FEATURE_NAMES_INPUT\n",
    "    # Ensure we only try to keep essential columns that actually exist\n",
    "    # Use SELECTED_FEATURE_NAMES_INPUT here\n",
    "    cols_to_keep = essential_cols_present + SELECTED_FEATURE_NAMES_INPUT\n",
    "\n",
    "    # Select final columns, ensuring all requested are present, filling missing with NaN\n",
    "    # This step ensures the final df has exactly the requested feature columns + essentials\n",
    "    final_df_structure = pd.DataFrame(index=df_combined.index)\n",
    "    present_cols_count = 0\n",
    "    missing_final_cols = []\n",
    "\n",
    "    for col in cols_to_keep:\n",
    "        if col in df_combined.columns:\n",
    "            final_df_structure[col] = df_combined[col]\n",
    "            # Count only actual features added\n",
    "            if col not in essential_cols_present:\n",
    "                present_cols_count += 1\n",
    "        else:\n",
    "            # This happens if a feature in SELECTED_FEATURE_NAMES_INPUT wasn't generated correctly\n",
    "            missing_final_cols.append(col)\n",
    "            final_df_structure[col] = np.nan\n",
    "\n",
    "    if missing_final_cols:\n",
    "        print(f\"  Final Warning: {len(missing_final_cols)} columns from SELECTED_FEATURE_NAMES_INPUT \"\n",
    "              f\"were missing in the combined df and added as NaN: {missing_final_cols}\")\n",
    "\n",
    "    # Final cleanup\n",
    "    final_df_structure = final_df_structure.reset_index(drop=True)\n",
    "    final_df_structure = final_df_structure.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    end_time = time.time()\n",
    "    actual_feature_count = len([col for col in final_df_structure.columns if col not in essential_cols_present])\n",
    "    print(f\"Selected feature calculation finished. Returning {len(final_df_structure)} rows, \"\n",
    "          f\"{len(final_df_structure.columns)} total columns ({actual_feature_count} features). \"\n",
    "          f\"Took {end_time - start_time:.2f}s.\")\n",
    "\n",
    "    # Verify final column count against the request\n",
    "    expected_feature_count = len(SELECTED_FEATURE_NAMES_INPUT) # Use Input list for check\n",
    "    if actual_feature_count != expected_feature_count:\n",
    "        # It's possible fewer were generated if prerequisites weren't met early on\n",
    "        print(f\"  NOTE: Expected {expected_feature_count} features based on SELECTED_FEATURE_NAMES_INPUT, \"\n",
    "              f\"but returning DataFrame with {actual_feature_count} non-essential features.\")\n",
    "\n",
    "    return final_df_structure\n",
    "\n",
    "\n",
    "# --- Main VIF Calculation Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- VIF Feature Selection Script ---\")\n",
    "\n",
    "    print(\"\\n--- 1. Data Loading & Initial Prep ---\")\n",
    "    try:\n",
    "        print(f\"Loading data from: {CSV_FILE_PATH}\")\n",
    "        col_names = ['unix', 'date', 'symbol_csv', 'open', 'high', 'low', 'close', 'Volume BTC', 'Volume USD']\n",
    "        df_raw = pd.read_csv(CSV_FILE_PATH, header=0, names=col_names)\n",
    "        print(f\"Raw data loaded. Shape: {df_raw.shape}\")\n",
    "        df_raw['timestamp'] = pd.to_datetime(df_raw['date'])\n",
    "        df_raw = df_raw.drop(['unix', 'date', 'symbol_csv'], axis=1)\n",
    "        df_raw = df_raw.sort_values('timestamp').reset_index(drop=True)\n",
    "        if df_raw.empty: exit(\"DataFrame empty after loading. Exiting.\")\n",
    "        print(f\"Initial data prep done. Shape: {df_raw.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing CSV: {e}\"); traceback.print_exc(); exit()\n",
    "\n",
    "    print(\"\\n--- 2. Feature Engineering (Generating 123 Features) ---\")\n",
    "    feature_calc_start = time.time()\n",
    "    # This function needs to be defined above or imported\n",
    "    df_with_123_features = calculate_selected_features(df_raw, symbol=SYMBOL_NAME)\n",
    "    feature_calc_end = time.time()\n",
    "    if df_with_123_features.empty: exit(\"Feature calculation failed. Exiting.\")\n",
    "    print(f\"Feature calculation completed in {feature_calc_end - feature_calc_start:.2f} seconds.\")\n",
    "\n",
    "    # Identify the actual feature columns present from the input list\n",
    "    actual_feature_cols = [col for col in SELECTED_FEATURE_NAMES_INPUT if col in df_with_123_features.columns]\n",
    "    if len(actual_feature_cols) != len(SELECTED_FEATURE_NAMES_INPUT):\n",
    "        print(f\"Warning: Only found {len(actual_feature_cols)} out of {len(SELECTED_FEATURE_NAMES_INPUT)} requested features in the generated DataFrame.\")\n",
    "    if not actual_feature_cols:\n",
    "        exit(\"Error: No features from the input list found in the generated DataFrame.\")\n",
    "\n",
    "    print(f\"\\n--- 3. Preparing Data for VIF (Using {len(actual_feature_cols)} features) ---\")\n",
    "    # Select only the feature columns for VIF calculation\n",
    "    X_features = df_with_123_features[actual_feature_cols].copy()\n",
    "\n",
    "    # Ensure all columns are numeric (attempt conversion, drop non-numeric if necessary)\n",
    "    for col in X_features.columns:\n",
    "        X_features[col] = pd.to_numeric(X_features[col], errors='coerce')\n",
    "    initial_cols = set(X_features.columns)\n",
    "    X_features = X_features.select_dtypes(include=np.number)\n",
    "    final_numeric_cols = set(X_features.columns)\n",
    "    dropped_non_numeric = initial_cols - final_numeric_cols\n",
    "    if dropped_non_numeric:\n",
    "        print(f\"  Warning: Dropped non-numeric columns before VIF: {dropped_non_numeric}\")\n",
    "    if X_features.empty:\n",
    "        exit(\"Error: No numeric feature columns left for VIF calculation.\")\n",
    "\n",
    "\n",
    "    # Impute missing values (necessary for VIF) - Using Median\n",
    "    print(f\"  Imputing NaNs using median strategy...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_features_imputed = imputer.fit_transform(X_features)\n",
    "    X_features_imputed_df = pd.DataFrame(X_features_imputed, columns=X_features.columns, index=X_features.index)\n",
    "    print(f\"  NaN count after imputation: {X_features_imputed_df.isnull().sum().sum()}\") # Should be 0\n",
    "\n",
    "    # Add constant for VIF calculation\n",
    "    print(\"  Adding constant for VIF calculation...\")\n",
    "    X_vif_ready = add_constant(X_features_imputed_df, has_constant='add')\n",
    "\n",
    "    print(\"\\n--- 4. Iterative VIF Calculation ---\")\n",
    "    print(f\"Starting VIF filtering with threshold {VIF_THRESHOLD}...\")\n",
    "\n",
    "    features_to_keep = list(X_features_imputed_df.columns) # Start with all numeric features\n",
    "    vif_data = X_vif_ready[features_to_keep + ['const']] # Select data including constant\n",
    "\n",
    "    dropped_features_count = 0\n",
    "    while True:\n",
    "        vif_results = pd.Series(\n",
    "            [variance_inflation_factor(vif_data.values, i)\n",
    "             for i in range(vif_data.shape[1] - 1)], # Exclude constant\n",
    "            index=features_to_keep, # Use current features as index\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "        max_vif = vif_results.max()\n",
    "        if max_vif > VIF_THRESHOLD:\n",
    "            feature_to_drop = vif_results.idxmax()\n",
    "            print(f\"  Dropping '{feature_to_drop}' with VIF: {max_vif:.4f}\")\n",
    "            features_to_keep.remove(feature_to_drop)\n",
    "            vif_data = vif_data.drop(columns=[feature_to_drop]) # Drop from the data used for next VIF calc\n",
    "            dropped_features_count += 1\n",
    "        else:\n",
    "            print(f\"  All remaining features have VIF <= {VIF_THRESHOLD}.\")\n",
    "            break # Exit loop\n",
    "\n",
    "        # Safety break in case of infinite loop (shouldn't happen)\n",
    "        if not features_to_keep:\n",
    "            print(\"  Warning: All features dropped during VIF process!\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n--- 5. VIF Selection Results ---\")\n",
    "    print(f\"VIF Threshold: {VIF_THRESHOLD}\")\n",
    "    print(f\"Original number of features considered: {len(actual_feature_cols)}\")\n",
    "    print(f\"Number of features dropped: {dropped_features_count}\")\n",
    "    print(f\"Number of features remaining: {len(features_to_keep)}\")\n",
    "    print(\"\\nFinal selected features (VIF < \" + str(VIF_THRESHOLD) + \"):\")\n",
    "    # Print the list in a readable format\n",
    "    print(\"SELECTED_FEATURE_NAMES_VIF_FILTERED = [\")\n",
    "    for i, feat in enumerate(features_to_keep):\n",
    "        print(f\"    '{feat}',\" + (\"\" if i == len(features_to_keep) - 1 else \"\"))\n",
    "    print(\"]\")\n",
    "\n",
    "    print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
